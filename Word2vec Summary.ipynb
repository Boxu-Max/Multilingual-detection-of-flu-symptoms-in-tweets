{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = pd.read_csv(\"NTCIR-13_MedWeb_en_training.csv\")\n",
    "test_en = pd.read_csv(\"NTCIR-13_MedWeb_en_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation inside\n",
    "import re\n",
    "def  clean_text_en(df, text_field): \n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update \n",
    "train_en = clean_text_en(train_en,\"Tweet\")\n",
    "test_en = clean_text_en(test_en,\"Tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset >>>\n"
     ]
    }
   ],
   "source": [
    "print('Processing text dataset >>>')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def text_to_wordlist(text, lower=False):\n",
    "    # Tokenize\n",
    "    text = tokenizer.tokenize(text)\n",
    "    return text\n",
    "\n",
    "def process_comments(list_sentences, lower=False):\n",
    "    comments = []\n",
    "    for text in list_sentences:\n",
    "        txt = text_to_wordlist(text, lower=lower)\n",
    "        comments.append(txt)\n",
    "    return comments\n",
    "\n",
    "list_train = list(train_en.Tweet)\n",
    "list_test = list(test_en.Tweet)\n",
    "\n",
    "tweet_train_en = process_comments(list_train)\n",
    "tweet_test_en = process_comments(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build word2vec model using Gensim\n",
      "Number of word vectors: 1814\n"
     ]
    }
   ],
   "source": [
    "print('Build word2vec model using Gensim')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tweet_train_en, size=100, window=3, min_count=1, sg=1, negative=15)\n",
    "word_vectors = model.wv\n",
    "print(\"Number of word vectors: {}\".format(len(word_vectors.vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('vectorvisual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load gensim word2vec\n",
    "w2v_path = 'vectorvisual'\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_path)\n",
    "\n",
    "import io\n",
    "\n",
    "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
    "\"\"\"\n",
    "0.1\\t0.2\\t0.5\\t0.9\n",
    "0.2\\t0.1\\t5.0\\t0.2\n",
    "0.4\\t0.1\\t7.0\\t0.8\n",
    "\"\"\"\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Meta data file, `\\n` seperated word\n",
    "\"\"\"\n",
    "token1\n",
    "token2\n",
    "token3\n",
    "\"\"\"\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Write meta file and vector file\n",
    "for index in range(len(w2v.index2word)):\n",
    "    word = w2v.index2word[index]\n",
    "    vec = w2v.vectors[index]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweet_train_en)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(tweet_train_en)\n",
    "X_test = tokenizer.texts_to_sequences(tweet_test_en)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "# word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 30\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "embedding_matrix = np.zeros((vocab_size,EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > vocab_size:\n",
    "        continue\n",
    "    embedding_vector = word_vectors[word]\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 100)           181500    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 27, 128)           51328     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13, 32)            4128      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 3336      \n",
      "=================================================================\n",
      "Total params: 240,292\n",
      "Trainable params: 240,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                     EMBEDDING_DIM,\n",
    "                     mask_zero=False,\n",
    "                     embeddings_initializer=Constant(embedding_matrix),\n",
    "                     input_length=maxlen,\n",
    "                     trainable=True)\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=128, kernel_size=4, padding='valid', activation='relu', strides=1))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, rankdir=\"LR\", show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"Influenza\", \"Diarrhea\",\"Hayfever\",\"Cough\",\"Headache\",\"Fever\",\"Runnynose\",\"Cold\"]\n",
    "result_train = train_en[list_classes].replace({'n':0, 'p':+1})\n",
    "y_train = result_train[list_classes].values\n",
    "\n",
    "result_test = test_en[list_classes].replace({'n':0, 'p':+1})\n",
    "y_test = result_test[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 640 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.5258 - accuracy: 0.8081 - val_loss: 0.3844 - val_accuracy: 0.8834\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.3881 - accuracy: 0.8754 - val_loss: 0.3678 - val_accuracy: 0.8834\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.3701 - accuracy: 0.8754 - val_loss: 0.3547 - val_accuracy: 0.8834\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.3609 - accuracy: 0.8754 - val_loss: 0.3467 - val_accuracy: 0.8834\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.3536 - accuracy: 0.8754 - val_loss: 0.3405 - val_accuracy: 0.8834\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.3448 - accuracy: 0.8754 - val_loss: 0.3338 - val_accuracy: 0.8834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.3321 - accuracy: 0.8757 - val_loss: 0.3218 - val_accuracy: 0.8838\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.3127 - accuracy: 0.8781 - val_loss: 0.3074 - val_accuracy: 0.8865\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.2864 - accuracy: 0.8891 - val_loss: 0.2897 - val_accuracy: 0.8967\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2576 - accuracy: 0.9000 - val_loss: 0.2766 - val_accuracy: 0.8990\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.2341 - accuracy: 0.9063 - val_loss: 0.2603 - val_accuracy: 0.9018\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.2090 - accuracy: 0.9158 - val_loss: 0.2484 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1909 - accuracy: 0.9242 - val_loss: 0.2443 - val_accuracy: 0.9098\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1723 - accuracy: 0.9318 - val_loss: 0.2342 - val_accuracy: 0.9123\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1555 - accuracy: 0.9409 - val_loss: 0.2282 - val_accuracy: 0.9162\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1425 - accuracy: 0.9459 - val_loss: 0.2200 - val_accuracy: 0.9209\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1287 - accuracy: 0.9515 - val_loss: 0.2203 - val_accuracy: 0.9225\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1162 - accuracy: 0.9575 - val_loss: 0.2117 - val_accuracy: 0.9266\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1047 - accuracy: 0.9622 - val_loss: 0.2049 - val_accuracy: 0.9268\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0920 - accuracy: 0.9693 - val_loss: 0.2010 - val_accuracy: 0.9311\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0825 - accuracy: 0.9740 - val_loss: 0.2009 - val_accuracy: 0.9287\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0747 - accuracy: 0.9768 - val_loss: 0.2006 - val_accuracy: 0.9332\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.1958 - val_accuracy: 0.9340\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0598 - accuracy: 0.9836 - val_loss: 0.1951 - val_accuracy: 0.9350\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.1931 - val_accuracy: 0.9365\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.1911 - val_accuracy: 0.9406\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0437 - accuracy: 0.9883 - val_loss: 0.1908 - val_accuracy: 0.9404\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0402 - accuracy: 0.9891 - val_loss: 0.1901 - val_accuracy: 0.9420\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.2048 - val_accuracy: 0.9359\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0330 - accuracy: 0.9923 - val_loss: 0.1963 - val_accuracy: 0.9400\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.1944 - val_accuracy: 0.9436\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.1988 - val_accuracy: 0.9430\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0247 - accuracy: 0.9945 - val_loss: 0.1982 - val_accuracy: 0.9402\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0230 - accuracy: 0.9951 - val_loss: 0.1972 - val_accuracy: 0.9418\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0206 - accuracy: 0.9959 - val_loss: 0.2054 - val_accuracy: 0.9400\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.2031 - val_accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ") # add early stopping\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[es])\n",
    "# class_weight=[{0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7},{0: 0.3, 1: 0.7},{0: 0.3, 1: 0.7},{0: 0.3, 1: 0.7},{0: 0.3, 1: 0.7},{0: 0.3, 1: 0.7}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influenza\n",
      "\n",
      "Test accuracy is 0.9703125\n",
      "Test precision is 0.5925925925925926\n",
      "Test recall is 0.6666666666666666\n",
      "Test f1-score is 0.627450980392157\n",
      "\n",
      "Diarrhea\n",
      "\n",
      "Test accuracy is 0.9671875\n",
      "Test precision is 0.8909090909090909\n",
      "Test recall is 0.765625\n",
      "Test f1-score is 0.823529411764706\n",
      "\n",
      "Hayfever\n",
      "\n",
      "Test accuracy is 0.959375\n",
      "Test precision is 0.7272727272727273\n",
      "Test recall is 0.6956521739130435\n",
      "Test f1-score is 0.711111111111111\n",
      "\n",
      "Cough\n",
      "\n",
      "Test accuracy is 0.93125\n",
      "Test precision is 0.86\n",
      "Test recall is 0.5375\n",
      "Test f1-score is 0.6615384615384615\n",
      "\n",
      "Headache\n",
      "\n",
      "Test accuracy is 0.94375\n",
      "Test precision is 0.8727272727272727\n",
      "Test recall is 0.6233766233766234\n",
      "Test f1-score is 0.7272727272727272\n",
      "\n",
      "Fever\n",
      "\n",
      "Test accuracy is 0.9234375\n",
      "Test precision is 0.7444444444444445\n",
      "Test recall is 0.7204301075268817\n",
      "Test f1-score is 0.7322404371584699\n",
      "\n",
      "Runnynose\n",
      "\n",
      "Test accuracy is 0.9109375\n",
      "Test precision is 0.8113207547169812\n",
      "Test recall is 0.6991869918699187\n",
      "Test f1-score is 0.7510917030567686\n",
      "\n",
      "Cold\n",
      "\n",
      "Test accuracy is 0.9296875\n",
      "Test precision is 0.8082191780821918\n",
      "Test recall is 0.6555555555555556\n",
      "Test f1-score is 0.7239263803680981\n",
      "\n",
      "Summary\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "The average accuracy is 0.9419921875\n",
      "The average precision is 0.7884357575931626\n",
      "The average recall is 0.6704991398635862\n",
      "The average f1 score is 0.7197701515828125\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "pred_test = model.predict(X_test)\n",
    "classes = pred_test > 0.5\n",
    "pred_test = classes.astype(int) # update predicted value\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# initialize\n",
    "ac = 0 \n",
    "pre = 0\n",
    "rec = 0\n",
    "f1_s = 0\n",
    "\n",
    "for i in range (0,8):\n",
    "    \n",
    "    prediction = pred_test[:, i]\n",
    "    y_sys = y_test[:,i]\n",
    "    print(list_classes[i])\n",
    "    print('\\nTest accuracy is {}'.format(accuracy_score(y_sys, prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(y_sys, prediction, average='binary')))\n",
    "    print('Test recall is {}'.format(recall_score(y_sys, prediction, average='binary')))\n",
    "    print('Test f1-score is {}\\n'.format(f1_score(y_sys, prediction, average='binary')))\n",
    "    \n",
    "    temp_accuracy = accuracy_score(y_sys, prediction)\n",
    "    ac = ac + temp_accuracy\n",
    "    \n",
    "    temp_precision = precision_score(y_sys, prediction, average='binary')\n",
    "    pre = pre + temp_precision\n",
    "    \n",
    "    temp_recall = recall_score(y_sys, prediction, average='binary')\n",
    "    rec = rec + temp_recall\n",
    "    \n",
    "    temp_f1_score = f1_score(y_sys, prediction, average='binary')\n",
    "    f1_s= f1_s + temp_f1_score\n",
    "\n",
    "print(\"Summary\\n>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "ava_accuracy = ac/8\n",
    "print('The average accuracy is {}'.format(ava_accuracy))\n",
    "\n",
    "ava_precision = pre/8\n",
    "print('The average precision is {}'.format(ava_precision))\n",
    "\n",
    "ava_recall = rec/8\n",
    "print('The average recall is {}'.format(ava_recall))\n",
    "\n",
    "ava_f1_score = f1_s/8\n",
    "print('The average f1 score is {}'.format(ava_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label='Test accuracy')\n",
    "    plt.title('Training and testing accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Test loss')\n",
    "    plt.title('Training and testing loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CNN_Eng.jpg\")\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_zh = pd.read_csv(\"NTCIR-13_MedWeb_zh_training.csv\", na_values='NaN',keep_default_na=False)\n",
    "test_zh = pd.read_csv(\"NTCIR-13_MedWeb_zh_test.csv\", na_values='NaN',keep_default_na=False)\n",
    "test_zh = test_zh[:640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation inside\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "\n",
    "def clean_text_zh(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem:re.sub(r'[{}]+'.format(punctuation),'',elem))\n",
    "    return df\n",
    "\n",
    "# update \n",
    "train_zh = clean_text_zh(train_zh,\"Tweet\")\n",
    "test_zh = clean_text_zh(test_zh,\"Tweet\")\n",
    "\n",
    "tweet_train_zh = list(train_zh.Tweet)\n",
    "tweet_test_zh = list(test_zh.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/xz/jrlb55l167x3c2jq466bx5fm0000gn/T/jieba.cache\n",
      "Loading model cost 0.818 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# introducing tokenizer\n",
    "import jieba\n",
    "\n",
    "def tokenize_zh(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "\n",
    "# Tokenization\n",
    "tweet_train_zh = [list(jieba.cut(i)) for i in tweet_train_zh]\n",
    "tweet_test_zh = [list(jieba.cut(i)) for i in tweet_test_zh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build word2vec model using Gensim\n",
      "Number of word vectors: 2292\n"
     ]
    }
   ],
   "source": [
    "print('Build word2vec model using Gensim')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tweet_train_zh, size=100, window=3, min_count=1, workers=3, sg=1)\n",
    "word_vectors = model.wv\n",
    "print(\"Number of word vectors: {}\".format(len(word_vectors.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('vectorvisualzh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load gensim word2vec\n",
    "w2v_path = 'vectorvisualzh'\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_path)\n",
    "\n",
    "import io\n",
    "\n",
    "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
    "\"\"\"\n",
    "0.1\\t0.2\\t0.5\\t0.9\n",
    "0.2\\t0.1\\t5.0\\t0.2\n",
    "0.4\\t0.1\\t7.0\\t0.8\n",
    "\"\"\"\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Meta data file, `\\n` seperated word\n",
    "\"\"\"\n",
    "token1\n",
    "token2\n",
    "token3\n",
    "\"\"\"\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Write meta file and vector file\n",
    "for index in range(len(w2v.index2word)):\n",
    "    word = w2v.index2word[index]\n",
    "    vec = w2v.vectors[index]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweet_train_zh)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(tweet_train_zh)\n",
    "X_test = tokenizer.texts_to_sequences(tweet_test_zh)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('了', 1), ('的', 2), ('是', 3), ('感冒', 4), ('得', 5), ('花粉症', 6), ('头疼', 7), ('很', 8), ('流感', 9), ('就', 10), ('因为', 11), ('也', 12), ('腹泻', 13), ('所以', 14), ('在', 15), ('发烧', 16), ('吧', 17), ('咳嗽', 18), ('好像', 19), ('啊', 20), ('鼻涕', 21), ('今天', 22), ('我', 23), ('开始', 24), ('都', 25), ('有', 26), ('好', 27), ('不', 28), ('吗', 29), ('去', 30), ('说', 31), ('严重', 32), ('会', 33), ('还', 34), ('时候', 35), ('厉害', 36), ('从', 37), ('早上', 38), ('要', 39), ('鼻塞', 40), ('疼', 41), ('又', 42), ('工作', 43), ('虽然', 44), ('没有', 45), ('人', 46), ('请假', 47), ('但', 48), ('药', 49), ('一直', 50), ('可能', 51), ('呢', 52), ('但是', 53), ('难受', 54), ('和', 55), ('上', 56), ('痰', 57), ('休息', 58), ('不能', 59), ('季节', 60), ('伤风', 61), ('着', 62), ('太', 63), ('痛苦', 64), ('能', 65), ('真的', 66), ('拉肚子', 67), ('不行', 68), ('对', 69), ('用', 70), ('被', 71), ('什么', 72), ('的话', 73), ('有点', 74), ('来', 75), ('想', 76), ('里', 77), ('这个', 78), ('最近', 79), ('烧', 80), ('这', 81), ('腮腺炎', 82), ('却', 83), ('吃', 84), ('头', 85), ('不妙', 86), ('一', 87), ('觉得', 88), ('禽流感', 89), ('没', 90), ('身体', 91), ('哥哥', 92), ('怎么', 93), ('发冷', 94), ('喝', 95), ('知道', 96), ('博客', 97), ('还是', 98), ('做', 99), ('医院', 100), ('无力', 101), ('症状', 102), ('今年', 103), ('腹肌', 104), ('到', 105), ('谁', 106), ('不停', 107), ('肚子疼', 108), ('结果', 109), ('不好', 110), ('春天', 111), ('打', 112), ('回家', 113), ('流鼻涕', 114), ('疫苗', 115), ('感染', 116), ('女儿', 117), ('东京', 118), ('以为', 119), ('西班牙', 120), ('明明', 121), ('有效', 122), ('已经', 123), ('据说', 124), ('英语', 125), ('没想到', 126), ('起来', 127), ('终于', 128), ('像是', 129), ('肚子', 130), ('咳得', 131), ('脑袋', 132), ('过', 133), ('不会', 134), ('这么', 135), ('狗', 136), ('跟', 137), ('听说', 138), ('淋巴', 139), ('起床', 140), ('睡', 141), ('现在', 142), ('出来', 143), ('糟', 144), ('昏昏沉沉', 145), ('真', 146), ('社团活动', 147), ('手机', 148), ('事', 149), ('感觉', 150), ('方法', 151), ('昨天', 152), ('止不住', 153), ('很多', 154), ('故意', 155), ('礼貌', 156), ('可以', 157), ('明天', 158), ('真是', 159), ('让', 160), ('需要', 161), ('盛行', 162), ('不是', 163), ('缘故', 164), ('肿', 165), ('口罩', 166), ('治疗', 167), ('中', 168), ('集体', 169), ('老婆', 170), ('明年', 171), ('地', 172), ('最', 173), ('发高烧', 174), ('新闻', 175), ('倦怠', 176), ('看', 177), ('咳', 178), ('应对', 179), ('好好', 180), ('对策', 181), ('昨晚', 182), ('尼泊尔', 183), ('病', 184), ('流行', 185), ('后', 186), ('预防', 187), ('高烧', 188), ('想起', 189), ('笑', 190), ('重要', 191), ('发热', 192), ('缓解', 193), ('把', 194), ('学校', 195), ('公司', 196), ('必须', 197), ('可怕', 198), ('睡觉', 199), ('为了', 200), ('是因为', 201), ('中国', 202), ('出门', 203), ('地方', 204), ('喜欢', 205), ('导致', 206), ('冷', 207), ('止住', 208), ('糟糕', 209), ('多', 210), ('翻译', 211), ('你', 212), ('弟弟', 213), ('一下', 214), (' ', 215), ('退烧药', 216), ('不要', 217), ('开发', 218), ('要是', 219), ('礼仪', 220), ('彻底', 221), ('流感疫苗', 222), ('听', 223), ('酸软', 224), ('出现', 225), ('发低烧', 226), ('居然', 227), ('会得', 228), ('花粉', 229), ('头痛', 230), ('过敏症', 231), ('快点', 232), ('应该', 233), ('好久没', 234), ('那个', 235), ('玩', 236), ('之后', 237), ('复发', 238), ('自己', 239), ('退', 240), ('差不多', 241), ('热', 242), ('传染', 243), ('过头', 244), ('停不下来', 245), ('希望', 246), ('旅行', 247), ('更', 248), ('妻子', 249), ('死', 250), ('舒服', 251), ('容易', 252), ('剧烈', 253), ('哦', 254), ('洗手', 255), ('还有', 256), ('超级', 257), ('请', 258), ('而且', 259), ('电视', 260), ('鼻子', 261), ('低烧', 262), ('盖饭', 263), ('没法', 264), ('正在', 265), ('因', 266), ('这样', 267), ('不断', 268), ('完全', 269), ('祖母', 270), ('只是', 271), ('而', 272), ('合同', 273), ('戴', 274), ('太妙', 275), ('想要', 276), ('给', 277), ('突然', 278), ('累', 279), ('巫女', 280), ('讨厌', 281), ('再', 282), ('流', 283), ('开', 284), ('回来', 285), ('秋天', 286), ('他', 287), ('连', 288), ('她', 289), ('大家', 290), ('早点', 291), ('问题', 292), ('浑身', 293), ('少', 294), ('对于', 295), ('泡澡', 296), ('作为', 297), ('时间', 298), ('想着', 299), ('患者', 300), ('告诉', 301), ('个', 302), ('许久', 303), ('可', 304), ('流个', 305), ('特别', 306), ('高兴', 307), ('时隔', 308), ('悬', 309), ('照片', 310), ('宇宙', 311), ('不止', 312), ('担心', 313), ('厕所', 314), ('开心', 315), ('样子', 316), ('好久', 317), ('宽松', 318), ('就算', 319), ('措施', 320), ('一个', 321), ('电车', 322), ('流得', 323), ('女性', 324), ('检查', 325), ('对方', 326), ('效果', 327), ('东西', 328), ('早早', 329), ('不过', 330), ('吐痰', 331), ('话', 332), ('止咳药', 333), ('朋友', 334), ('像', 335), ('音乐', 336), ('采取', 337), ('晕晕沉沉', 338), ('停', 339), ('上班', 340), ('来说', 341), ('无法', 342), ('喝药', 343), ('引起', 344), ('才', 345), ('真没想到', 346), ('回去', 347), ('外出', 348), ('时', 349), ('真是太', 350), ('危机', 351), ('便当', 352), ('后背', 353), ('如果', 354), ('管用', 355), ('过度', 356), ('轻微', 357), ('不想', 358), ('乏力', 359), ('食物中毒', 360), ('喉咙', 361), ('健康', 362), ('治', 363), ('管理', 364), ('哪个', 365), ('痊愈', 366), ('?', 367), ('科学', 368), ('不管', 369), ('很少', 370), ('只有', 371), ('世代', 372), ('太糟', 373), ('原因', 374), ('加', 375), ('非常', 376), ('家伙', 377), ('防治', 378), ('感冒药', 379), ('剧烈地', 380), ('医生', 381), ('买', 382), ('时期', 383), ('麻烦', 384), ('漱口', 385), ('晕晕乎乎', 386), ('挺', 387), ('且', 388), ('快', 389), ('感到', 390), ('写', 391), ('关于', 392), ('足球', 393), ('嗓子', 394), ('绝对', 395), ('退烧', 396), ('早退', 397), ('病毒', 398), ('流着', 399), ('疼痛', 400), ('意思', 401), ('变得', 402), ('每年', 403), ('难得', 404), ('这次', 405), ('决定', 406), ('真糟糕', 407), ('就是', 408), ('一样', 409), ('即便', 410), ('告知', 411), ('是不是', 412), ('读', 413), ('没事', 414), ('传播', 415), ('必要', 416), ('解决', 417), ('总', 418), ('血', 419), ('狗狗', 420), ('呀', 421), ('捂着', 422), ('凉快', 423), ('生病', 424), ('体液', 425), ('用手', 426), ('状态', 427), ('不太好', 428), ('看到', 429), ('这是', 430), ('发', 431), ('难道', 432), ('家里', 433), ('小心', 434), ('刚刚', 435), ('治不好', 436), ('办法', 437), ('考试', 438), ('除了', 439), ('澡', 440), ('竟然', 441), ('发着', 442), ('出', 443), ('我家', 444), ('比', 445), ('吃药', 446), ('前', 447), ('为', 448), ('社团', 449), ('大', 450), ('去年', 451), ('恢复', 452), ('持续', 453), ('很久没', 454), ('奇怪', 455), ('糟透了', 456), ('先', 457), ('由于', 458), ('迹象', 459), ('着凉', 460), ('其实', 461), ('量', 462), ('过去', 463), ('地流', 464), ('成年', 465), ('戴着', 466), ('原来', 467), ('看电视', 468), ('立刻', 469), ('嘴巴', 470), ('饶', 471), ('凉爽', 472), ('精神', 473), ('握手', 474), ('腹痛', 475), ('困扰', 476), ('不好受', 477), ('对付', 478), ('危险', 479), ('烦人', 480), ('力气', 481), ('下', 482), ('我要', 483), ('加油', 484), ('一整天', 485), ('情况', 486), ('那', 487), ('日本', 488), ('之前', 489), ('倒', 490), ('比较', 491), ('疗法', 492), ('无论如何', 493), ('装', 494), ('到底', 495), ('每天', 496), ('干', 497), ('不了', 498), ('嘴', 499), ('果然', 500), ('里面', 501), ('注意', 502), ('恐怖', 503), ('柏树', 504), ('旁边', 505), ('辛苦', 506), ('一周', 507), ('刚才', 508), ('过敏', 509), ('外面', 510), ('电视新闻', 511), ('眼睛', 512), ('度', 513), ('开来', 514), ('诊断', 515), ('服', 516), ('太好了', 517), ('我会', 518), ('打工', 519), ('会议', 520), ('爆笑', 521), ('患有', 522), ('擤', 523), ('年', 524), ('一点', 525), ('程度', 526), ('副作用', 527), ('体温', 528), ('不少', 529), ('烧着', 530), ('别的', 531), ('酸懒', 532), ('遵守', 533), ('老', 534), ('怎么样', 535), ('一看', 536), ('想到', 537), ('只能', 538), ('类似', 539), ('立马', 540), ('引发', 541), ('做手术', 542), ('回', 543), ('加上', 544), ('空调', 545), ('完', 546), ('提前', 547), ('有些', 548), ('点', 549), ('不去', 550), ('接种', 551), ('抑制', 552), ('假装', 553), ('为什么', 554), ('看着', 555), ('咳个', 556), ('以外', 557), ('睡着', 558), ('稍微', 559), ('是否', 560), ('说来', 561), ('不得', 562), ('经常', 563), ('肚子痛', 564), ('拿到', 565), ('有人', 566), ('话题', 567), ('交替', 568), ('治好', 569), ('水', 570), ('很难', 571), ('登革热', 572), ('穿', 573), ('瞬间', 574), ('成', 575), ('大概', 576), ('成为', 577), ('捂住', 578), ('吐', 579), ('忘', 580), ('痢疾', 581), ('疼得', 582), ('喷', 583), ('带', 584), ('礼物', 585), ('没得', 586), ('困', 587), ('与', 588), ('心情', 589), ('家', 590), ('肯定', 591), ('怪', 592), ('困困', 593), ('很困', 594), ('混', 595), ('关系', 596), ('一种', 597), ('足球比赛', 598), ('止', 599), ('呼吸', 600), ('体力', 601), ('哪儿', 602), ('减轻', 603), ('人前', 604), ('礼节', 605), ('受不了', 606), ('闹肚子', 607), ('叫', 608), ('意识', 609), ('即使', 610), ('不得了', 611), ('降温', 612), ('是从', 613), ('噩梦', 614), ('疾病', 615), ('高', 616), ('那里', 617), ('假', 618), ('啦', 619), ('怎么办', 620), ('忙', 621), ('做好', 622), ('准备', 623), ('吓了一跳', 624), ('集中精力', 625), ('发生', 626), ('疲惫', 627), ('看看', 628), ('例子', 629), ('飞散', 630), ('很累', 631), ('同样', 632), ('全都', 633), ('之类', 634), ('好烦', 635), ('边', 636), ('好笑', 637), ('等', 638), ('天气', 639), ('不得不', 640), ('3', 641), ('虽说', 642), ('至今', 643), ('加重', 644), ('死亡', 645), ('由', 646), ('孩子', 647), ('针对', 648), ('进展', 649), ('总之', 650), ('各种', 651), ('年纪', 652), ('考虑', 653), ('烦恼', 654), ('引得', 655), ('完美', 656), ('多少', 657), ('报道', 658), ('拜托', 659), ('他们', 660), ('跑', 661), ('热情', 662), ('来势', 663), ('汹涌', 664), ('泡个', 665), ('然后', 666), ('酸奶', 667), ('本来', 668), ('胸口', 669), ('打喷嚏', 670), ('使劲', 671), ('不同', 672), ('努力', 673), ('洗澡', 674), ('一会儿', 675), ('目的地', 676), ('歪', 677), ('烦躁', 678), ('发展', 679), ('腹部', 680), ('日子', 681), ('茶', 682), ('肠胃', 683), ('别', 684), ('简直', 685), ('令人', 686), ('前夕', 687), ('每次', 688), ('变成', 689), ('为止', 690), ('没退', 691), ('泡', 692), ('不错', 693), ('发病', 694), ('第一次', 695), ('不久', 696), ('参加', 697), ('按', 698), ('连续', 699), ('便宜', 700), ('到来', 701), ('温柔', 702), ('差点', 703), ('犯', 704), ('说起', 705), ('中招', 706), ('一边', 707), ('一般', 708), ('郁闷', 709), ('那么', 710), ('跟着', 711), ('处理', 712), ('停止', 713), ('周围', 714), ('平时', 715), ('似的', 716), ('眼镜', 717), ('新', 718), ('可是', 719), ('那种', 720), ('大事', 721), ('没什么', 722), ('问', 723), ('尤其', 724), ('更新', 725), ('有点儿', 726), ('真累', 727), ('变', 728), ('亲子', 729), ('蔓延', 730), ('中止', 731), ('进行', 732), ('声音', 733), ('好多', 734), ('不用', 735), ('妈妈', 736), ('吃饭', 737), ('强效', 738), ('莫非', 739), ('注射', 740), ('理解', 741), ('单纯', 742), ('初期', 743), ('胸', 744), ('寒冷', 745), ('打算', 746), ('很差', 747), ('渴', 748), ('左右', 749), ('季节性', 750), ('段时间', 751), ('看起来', 752), ('烧退', 753), ('实在', 754), ('手', 755), ('传染病', 756), ('纸巾', 757), ('说明', 758), ('秋季', 759), ('观看', 760), ('通过', 761), ('区区', 762), ('搞笑', 763), ('不知不觉', 764), ('使用', 765), ('花', 766), ('浪费', 767), ('只', 768), ('打针', 769), ('害怕', 770), ('信息', 771), ('偏偏', 772), ('这回', 773), ('有种', 774), ('不到', 775), ('耳鼻喉科', 776), ('鼻窦炎', 777), ('热得', 778), ('放在', 779), ('换季', 780), ('很强', 781), ('再次', 782), ('还会', 783), ('疲累', 784), ('一天', 785), ('婴儿', 786), ('种', 787), ('掺血', 788), ('结束', 789), ('尝试', 790), ('抽筋', 791), ('一去', 792), ('戴上', 793), ('头盔', 794), ('不算', 795), ('头太疼', 796), ('赶快', 797), ('输给', 798), ('传到', 799), ('累人', 800), ('风', 801), ('头晕', 802), ('教教', 803), ('治愈', 804), ('通气', 805), ('该', 806), ('不够', 807), ('呐', 808), ('欠佳', 809), ('排出来', 810), ('热量', 811), ('料理', 812), ('明显', 813), ('就要', 814), ('增加', 815), ('月', 816), ('痛', 817), ('人少', 818), ('才能', 819), ('危机感', 820), ('莫名', 821), ('小', 822), ('不该', 823), ('特效药', 824), ('之余', 825), ('关节', 826), ('难办', 827), ('透', 828), ('今早', 829), ('错觉', 830), ('鸟类', 831), ('家务', 832), ('按摩', 833), ('冷得', 834), ('大部分', 835), ('懂', 836), ('签合同', 837), ('发现', 838), ('坏', 839), ('依然', 840), ('盒饭', 841), ('爱', 842), ('当然', 843), ('吓人', 844), ('只要', 845), ('拿', 846), ('正在流行', 847), ('普通', 848), ('定期', 849), ('咳痰', 850), ('帮帮忙', 851), ('毒素', 852), ('救', 853), ('嗡嗡地', 854), ('没准', 855), ('发表', 856), ('女', 857), ('抱歉', 858), ('一次', 859), ('握', 860), ('照顾', 861), ('太难受', 862), ('忘记', 863), ('歌', 864), ('放到', 865), ('关心', 866), ('重感冒', 867), ('差劲', 868), ('真让人', 869), ('烧得', 870), ('禁止', 871), ('肌肉', 872), ('耳机', 873), ('源头', 874), ('惨', 875), ('过来', 876), ('幼儿园', 877), ('证据', 878), ('怎么回事', 879), ('却是', 880), ('起不来', 881), ('肿起来', 882), ('神社', 883), ('压力', 884), ('福', 885), ('苦笑', 886), ('很大', 887), ('镜头', 888), ('吵', 889), ('第二天', 890), ('脖子', 891), ('大会', 892), ('流出', 893), ('一起', 894), ('没停', 895), ('要死', 896), ('社会', 897), ('总是', 898), ('救救', 899), ('发布', 900), ('老实', 901), ('不光', 902), ('牛肉', 903), ('前辈', 904), ('塞得', 905), ('难', 906), ('男', 907), ('三天', 908), ('传说', 909), ('咽下去', 910), ('根源', 911), ('躺', 912), ('粥', 913), ('选手', 914), ('应试', 915), ('生', 916), ('疑似', 917), ('症', 918), ('等等', 919), ('放松', 920), ('诺瓦克', 921), ('完蛋', 922), ('传达', 923), ('混着', 924), ('依旧', 925), ('肿着', 926), ('想想', 927), ('不安', 928), ('塞', 929), ('关注', 930), ('直接', 931), ('汇集', 932), ('简单', 933), ('处方药', 934), ('困得', 935), ('好转', 936), ('刚', 937), ('周末', 938), ('排出去', 939), ('或许', 940), ('鼻', 941), ('冷天', 942), ('冬天', 943), ('面试', 944), ('没戏', 945), ('往年', 946), ('丈夫', 947), ('意外', 948), ('能够', 949), ('小孩子', 950), ('没想', 951), ('一点点', 952), ('快要', 953), ('刻意', 954), ('力量', 955), ('体魄', 956), ('耳麦', 957), ('侵袭', 958), ('脑子', 959), ('紧', 960), ('重复', 961), ('能否', 962), ('鸟', 963), ('附近', 964), ('以前', 965), ('回忆', 966), ('约会', 967), ('回到', 968), ('事情', 969), ('迟到', 970), ('读书', 971), ('最糟', 972), ('掩', 973), ('接近', 974), ('锻炼', 975), ('久', 976), ('昏昏', 977), ('药物', 978), ('认为', 979), ('哭', 980), ('掺', 981), ('照', 982), ('而是', 983), ('兴奋', 984), ('眼泪', 985), ('踢足球', 986), ('拿药', 987), ('不明', 988), ('吸溜', 989), ('40', 990), ('好处', 991), ('反而', 992), ('今晚', 993), ('丢人', 994), ('苦于', 995), ('光是', 996), ('烦', 997), ('住', 998), ('太吵', 999), ('所', 1000), ('惊讶', 1001), ('事故', 1002), ('比赛', 1003), ('部', 1004), ('患上', 1005), ('大夫', 1006), ('推荐', 1007), ('成人', 1008), ('扑杀', 1009), ('羡慕', 1010), ('预防接种', 1011), ('疲劳', 1012), ('会少', 1013), ('没劲儿', 1014), ('卧床', 1015), ('一听', 1016), ('场面', 1017), ('轻', 1018), ('停下来', 1019), ('喷嚏', 1020), ('型', 1021), ('晚上', 1022), ('赶紧', 1023), ('趁着', 1024), ('排斥', 1025), ('请教', 1026), ('以上', 1027), ('呆', 1028), ('那样', 1029), ('姑且', 1030), ('更加', 1031), ('接触', 1032), ('咽喉', 1033), ('出去', 1034), ('炸', 1035), ('件', 1036), ('拉', 1037), ('渐渐', 1038), ('停下', 1039), ('转换', 1040), ('散步', 1041), ('厚生', 1042), ('劳动', 1043), ('省', 1044), ('好惨', 1045), ('无论', 1046), ('恶心', 1047), ('从不', 1048), ('其间', 1049), ('苦不堪言', 1050), ('晕晕', 1051), ('认识', 1052), ('轻视', 1053), ('喝太多', 1054), ('曾', 1055), ('发昏', 1056), ('第二次', 1057), ('核事故', 1058), ('造成', 1059), ('辐射', 1060), ('下降', 1061), ('过于', 1062), ('摧残', 1063), ('顺利', 1064), ('签下来', 1065), ('预防针', 1066), ('伴随', 1067), ('特效', 1068), ('连水', 1069), ('依靠', 1070), ('免疫力', 1071), ('尽可能', 1072), ('研制', 1073), ('乘坐', 1074), ('别以为', 1075), ('感个', 1076), ('冒', 1077), ('恶化', 1078), ('从事', 1079), ('从没', 1080), ('很着急', 1081), ('毕竟', 1082), ('手术', 1083), ('嗯', 1084), ('负责人', 1085), ('时刻', 1086), ('呈', 1087), ('指数', 1088), ('增长', 1089), ('忽然', 1090), ('家族', 1091), ('成员', 1092), ('第一个', 1093), ('有软', 1094), ('面巾纸', 1095), ('拒绝', 1096), ('能止', 1097), ('食物', 1098), ('喽', 1099), ('一早', 1100), ('不太懂', 1101), ('可药开', 1102), ('国内', 1103), ('制度', 1104), ('并', 1105), ('完备', 1106), ('漏洞百出', 1107), ('容器', 1108), ('睡多', 1109), ('它', 1110), ('办', 1111), ('偶像', 1112), ('温床', 1113), ('感染力', 1114), ('一部分', 1115), ('签约', 1116), ('事头', 1117), ('帮帮我', 1118), ('鼻炎', 1119), ('其它', 1120), ('最终', 1121), ('感染性', 1122), ('强', 1123), ('咖啡', 1124), ('蹭', 1125), ('电脑', 1126), ('试着', 1127), ('防护眼镜', 1128), ('听大', 1129), ('声响', 1130), ('确信', 1131), ('练', 1132), ('休假', 1133), ('热衷', 1134), ('有课', 1135), ('洗鼻器', 1136), ('勇气', 1137), ('各种各样', 1138), ('模式', 1139), ('一碰', 1140), ('性价比', 1141), ('常年', 1142), ('药后', 1143), ('事来', 1144), ('查', 1145), ('喝完', 1146), ('时节', 1147), ('既', 1148), ('小孩', 1149), ('数年', 1150), ('肿得', 1151), ('万全', 1152), ('蜜蜂', 1153), ('肿涨', 1154), ('联系', 1155), ('挡', 1156), ('回家吧', 1157), ('八成', 1158), ('绝不能', 1159), ('拍照片', 1160), ('名为', 1161), ('.', 1162), ('兼顾', 1163), ('水痘', 1164), ('内科', 1165), ('前不去', 1166), ('这下', 1167), ('篇', 1168), ('文章', 1169), ('肿胀', 1170), ('家庭成员', 1171), ('预测', 1172), ('装备', 1173), ('写入', 1174), ('!', 1175), ('魩', 1176), ('仔鱼', 1177), ('这儿', 1178), ('一位', 1179), ('打电话', 1180), ('写道', 1181), ('游乐场', 1182), ('太狠', 1183), ('汽车', 1184), ('使', 1185), ('以后', 1186), ('生活', 1187), ('疼过', 1188), ('路上', 1189), ('美丽', 1190), ('老老实实', 1191), ('檜树', 1192), ('灭绝', 1193), ('老家', 1194), ('寄来', 1195), ('爱犬', 1196), ('身影', 1197), ('利索', 1198), ('西红柿', 1199), ('喉咙痛', 1200), ('科技进步', 1201), ('世上', 1202), ('多种', 1203), ('每种', 1204), ('研究', 1205), ('红色', 1206), ('疼且', 1207), ('有时', 1208), ('会变', 1209), ('难吃', 1210), ('挣扎', 1211), ('小时', 1212), ('后连头', 1213), ('那天', 1214), ('粗枝大叶', 1215), ('一和狗', 1216), ('喉咙干', 1217), ('最后', 1218), ('凑合', 1219), ('困了', 1220), ('要命', 1221), ('那位', 1222), ('太多', 1223), ('表达', 1224), ('新型', 1225), ('完善', 1226), ('设备', 1227), ('管理体制', 1228), ('干下', 1229), ('保姆', 1230), ('儿时', 1231), ('回事儿', 1232), ('全无', 1233), ('慌忙', 1234), ('同时', 1235), ('很花', 1236), ('超爱', 1237), ('冷却', 1238), ('生姜', 1239), ('汤', 1240), ('吃惊', 1241), ('杉树', 1242), ('量会', 1243), ('前景', 1244), ('克制', 1245), ('狂玩', 1246), ('很惨', 1247), ('发得', 1248), ('找到', 1249), ('您', 1250), ('证明', 1251), ('重度', 1252), ('增减', 1253), ('意义', 1254), ('做到', 1255), ('电脑前', 1256), ('故障', 1257), ('常备', 1258), ('店里', 1259), ('累累', 1260), ('不但', 1261), ('轻度', 1262), ('各式各样', 1263), ('出不来', 1264), ('自我管理', 1265), ('斗争', 1266), ('在读', 1267), ('博主', 1268), ('计划', 1269), ('惯性', 1270), ('地去', 1271), ('响', 1272), ('不仅仅', 1273), ('堵', 1274), ('多亏', 1275), ('坚决', 1276), ('吸吸', 1277), ('溜溜', 1278), ('可怜', 1279), ('连门', 1280), ('似地', 1281), ('源于', 1282), ('含着', 1283), ('超烂', 1284), ('学分', 1285), ('度会', 1286), ('性别', 1287), ('全是', 1288), ('不仅', 1289), ('睡眠不足', 1290), ('好些', 1291), ('勉强', 1292), ('工', 1293), ('以', 1294), ('身体素质', 1295), ('练习', 1296), ('使得', 1297), ('感觉不好', 1298), ('受', 1299), ('奶奶', 1300), ('无数次', 1301), ('落地', 1302), ('怎样', 1303), ('老师', 1304), ('时要', 1305), ('保持', 1306), ('过手', 1307), ('几次', 1308), ('舞台', 1309), ('戴假发', 1310), ('发套', 1311), ('想象', 1312), ('片刻', 1313), ('不离', 1314), ('有毒', 1315), ('呕吐', 1316), ('真想', 1317), ('做点', 1318), ('多半', 1319), ('一说', 1320), ('同事', 1321), ('那家伙', 1322), ('享受', 1323), ('蹩脚', 1324), ('耳朵', 1325), ('难听', 1326), ('不流', 1327), ('假期', 1328), ('喂', 1329), ('看样子', 1330), ('并发症', 1331), ('中不戴', 1332), ('早起', 1333), ('没完', 1334), ('可爱', 1335), ('消失', 1336), ('浓痰', 1337), ('要求', 1338), ('老疼', 1339), ('唉', 1340), ('光', 1341), ('差', 1342), ('折磨', 1343), ('中途', 1344), ('告白', 1345), ('一心', 1346), ('大喊', 1347), ('疲倦', 1348), ('感', 1349), ('来信', 1350), ('来杯', 1351), ('海带', 1352), ('脆弱', 1353), ('必', 1354), ('平安无事', 1355), ('时常', 1356), ('小看', 1357), ('客户', 1358), ('流像', 1359), ('通信', 1360), ('学生', 1361), ('连用', 1362), ('手掩', 1363), ('集体生活', 1364), ('活着', 1365), ('咳着', 1366), ('下车', 1367), ('追星', 1368), ('仲夏', 1369), ('梦幻', 1370), ('看病', 1371), ('床', 1372), ('就行了', 1373), ('工在', 1374), ('招人', 1375), ('应聘', 1376), ('保养', 1377), ('托', 1378), ('决赛', 1379), ('划时代', 1380), ('上周', 1381), ('恢复健康', 1382), ('音乐会', 1383), ('药会', 1384), ('科学家', 1385), ('招待', 1386), ('供', 1387), ('祖宗', 1388), ('蒙混', 1389), ('擦', 1390), ('小学', 1391), ('时代', 1392), ('保健室', 1393), ('放屁', 1394), ('喷出', 1395), ('稀来', 1396), ('嘲笑', 1397), ('寄养', 1398), ('时刚', 1399), ('说完', 1400), ('人生', 1401), ('延迟', 1402), ('下周', 1403), ('脑浆', 1404), ('预想', 1405), ('种类', 1406), ('制造', 1407), ('演唱会', 1408), ('最好', 1409), ('两周', 1410), ('加急', 1411), ('周六日', 1412), ('搭进去', 1413), ('为此', 1414), ('不出', 1415), ('意料', 1416), ('提交', 1417), ('报告', 1418), ('建议', 1419), ('流太多', 1420), ('机场', 1421), ('送过来', 1422), ('病人', 1423), ('厚', 1424), ('劳省', 1425), ('被子', 1426), ('到极点', 1427), ('译本', 1428), ('推特', 1429), ('接收', 1430), ('来自', 1431), ('电波', 1432), ('烧不退', 1433), ('站', 1434), ('卫生', 1435), ('饭馆', 1436), ('谜', 1437), ('上衣', 1438), ('递给', 1439), ('不太会', 1440), ('发音', 1441), ('大笑', 1442), ('误以为', 1443), ('全', 1444), ('明星阵容', 1445), ('发干', 1446), ('能练', 1447), ('直到', 1448), ('多福', 1449), ('有火', 1450), ('多幅', 1451), ('火', 1452), ('人物', 1453), ('超', 1454), ('充血', 1455), ('控制', 1456), ('手机电池', 1457), ('扩大', 1458), ('憋不住', 1459), ('太脏', 1460), ('讲', 1461), ('倒下', 1462), ('打个', 1463), ('完事', 1464), ('调查', 1465), ('挺烦', 1466), ('策略', 1467), ('病倒', 1468), ('39', 1469), ('撒欢儿', 1470), ('相信', 1471), ('新闻报道', 1472), ('快速', 1473), ('浴室', 1474), ('半身', 1475), ('浴', 1476), ('一员', 1477), ('没用', 1478), ('天', 1479), ('32', 1480), ('万', 1481), ('家鸭', 1482), ('鸡', 1483), ('旅游', 1484), ('人得', 1485), ('听听', 1486), ('中任', 1487), ('思维', 1488), ('驰骋', 1489), ('观测', 1490), ('天体', 1491), ('喝点', 1492), ('柠檬汁', 1493), ('早饭', 1494), ('不对劲', 1495), ('都行', 1496), ('发明', 1497), ('传染给', 1498), ('越来越', 1499), ('似乎', 1500), ('根本', 1501), ('当回事', 1502), ('词', 1503), ('词典', 1504), ('英语翻译', 1505), ('现实', 1506), ('生气', 1507), ('真真', 1508), ('观察', 1509), ('搞混', 1510), ('还要', 1511), ('会儿', 1512), ('没能', 1513), ('烧倒', 1514), ('下面', 1515), ('栓', 1516), ('应当', 1517), ('剧烈运动', 1518), ('书', 1519), ('不靠', 1520), ('谱', 1521), ('网上', 1522), ('可疑', 1523), ('民间', 1524), ('接受', 1525), ('动物', 1526), ('杀死', 1527), ('政府', 1528), ('粗暴', 1529), ('1', 1530), ('万日元', 1531), ('轻轻松松', 1532), ('能付', 1533), ('表亲', 1534), ('改', 1535), ('时戴', 1536), ('多喝水', 1537), ('差一点儿', 1538), ('不疼', 1539), ('睡过去', 1540), ('正得', 1541), ('官厅', 1542), ('外', 1543), ('出世', 1544), ('田谷区', 1545), ('各位', 1546), ('对不住', 1547), ('怪病', 1548), ('事变', 1549), ('课程', 1550), ('掺着', 1551), ('可头', 1552), ('小满', 1553), ('看上去', 1554), ('感染者', 1555), ('骂', 1556), ('笨蛋', 1557), ('在家', 1558), ('年初', 1559), ('拜', 1560), ('穿成', 1561), ('不好办', 1562), ('除', 1563), ('难过', 1564), ('包括', 1565), ('典型', 1566), ('晚饭', 1567), ('美味', 1568), ('拍照', 1569), ('全然', 1570), ('再不去', 1571), ('流行起来', 1572), ('药时', 1573), ('能治', 1574), ('真烦', 1575), ('止咳', 1576), ('抽', 1577), ('抽地', 1578), ('本人', 1579), ('哼', 1580), ('大人', 1581), ('昏睡', 1582), ('停过', 1583), ('课题', 1584), ('不让', 1585), ('海外', 1586), ('切身感受', 1587), ('完成', 1588), ('下午', 1589), ('平常', 1590), ('查克', 1591), ('之旅', 1592), ('依照', 1593), ('练就', 1594), ('强壮', 1595), ('一戴上', 1596), ('引', 1597), ('职', 1598), ('场里', 1599), ('咔擦', 1600), ('咔嚓', 1601), ('地响', 1602), ('堵着', 1603), ('睡不着', 1604), ('错过', 1605), ('时机', 1606), ('床上', 1607), ('后得会', 1608), ('通红', 1609), ('急急忙忙', 1610), ('签了', 1611), ('途中', 1612), ('香', 1613), ('字', 1614), ('唯独', 1615), ('别流', 1616), ('一肿', 1617), ('比起', 1618), ('次', 1619), ('长时间', 1620), ('进步', 1621), ('好受', 1622), ('太差', 1623), ('困又乏', 1624), ('一吃', 1625), ('总会', 1626), ('腹泄', 1627), ('海鲜', 1628), ('慢慢', 1629), ('动弹', 1630), ('做饭', 1631), ('推迟', 1632), ('对不起', 1633), ('区别', 1634), ('内部', 1635), ('于是', 1636), ('暖炉', 1637), ('桌下', 1638), ('小憩', 1639), ('特辑', 1640), ('微妙', 1641), ('起效', 1642), ('粉丝', 1643), ('接着', 1644), ('通勤', 1645), ('烦死', 1646), ('将', 1647), ('足球队', 1648), ('不由', 1649), ('针', 1650), ('原以为', 1651), ('发了', 1652), ('弄错', 1653), ('最佳', 1654), ('沉沉的', 1655), ('真糟', 1656), ('发起烧来', 1657), ('思考', 1658), ('忧郁', 1659), ('训斥', 1660), ('我个', 1661), ('说会', 1662), ('散热', 1663), ('睁眼', 1664), ('意料之中', 1665), ('上读', 1666), ('累且', 1667), ('约定', 1668), ('抗争', 1669), ('洗完', 1670), ('澡后', 1671), ('头发', 1672), ('没弄', 1673), ('粘液', 1674), ('服太', 1675), ('单薄', 1676), ('领导', 1677), ('没完没了', 1678), ('脸肿', 1679), ('咽', 1680), ('技巧', 1681), ('一刻不停', 1682), ('嘛', 1683), ('搭', 1684), ('伴儿', 1685), ('呵呵', 1686), ('低落', 1687), ('狂', 1688), ('晚睡', 1689), ('过后', 1690), ('疼太糟', 1691), ('误诊', 1692), ('成是', 1693), ('女朋友', 1694), ('心想', 1695), ('硬用', 1696), ('上演', 1697), ('卷入', 1698), ('道', 1699), ('坏人', 1700), ('很渴', 1701), ('便利店', 1702), ('闷', 1703), ('第', 1704), ('天想', 1705), ('意料之外', 1706), ('里流', 1707), ('淋巴腺', 1708), ('要说', 1709), ('晚', 1710), ('暖和', 1711), ('太凉', 1712), ('或是', 1713), ('昏沉沉', 1714), ('床头', 1715), ('积累', 1716), ('便秘', 1717), ('反复', 1718), ('擅长', 1719), ('泳衣', 1720), ('流鼻血', 1721), ('微烧', 1722), ('咖啡厅', 1723), ('生水', 1724), ('当', 1725), ('弄坏', 1726), ('优君得', 1727), ('仅仅', 1728), ('见到', 1729), ('想见', 1730), ('这份', 1731), ('解放出来', 1732), ('超疼', 1733), ('裂开', 1734), ('梦话', 1735), ('盖', 1736), ('饭后', 1737), ('手帕', 1738), ('掩着', 1739), ('想成', 1740), ('出错', 1741), ('争吵', 1742), ('顺带', 1743), ('到达', 1744), ('紧张', 1745), ('顶点', 1746), ('润喉', 1747), ('糖', 1748), ('倒不如', 1749), ('马路上', 1750), ('地流个', 1751), ('怪怪的', 1752), ('现代科学', 1753), ('智慧', 1754), ('却没能', 1755), ('研发', 1756), ('但头', 1757), ('试试', 1758), ('呗', 1759), ('蜂蜜', 1760), ('接电话', 1761), ('打错', 1762), ('一下子', 1763), ('能治好', 1764), ('新药', 1765), ('易得', 1766), ('连头', 1767), ('数日', 1768), ('外加', 1769), ('弱点', 1770), ('山', 1771), ('频繁', 1772), ('工就', 1773), ('全身', 1774), ('变凉', 1775), ('追加', 1776), ('文件', 1777), ('好险', 1778), ('后头', 1779), ('唱', 1780), ('卡拉', 1781), ('ok', 1782), ('别想', 1783), ('用药', 1784), ('中心', 1785), ('四肢无力', 1786), ('身体状况', 1787), ('很棒', 1788), ('者', 1789), ('郁结', 1790), ('于', 1791), ('检查一下', 1792), ('一刮', 1793), ('大风', 1794), ('厌烦', 1795), ('积攒', 1796), ('节电', 1797), ('慎重对待', 1798), ('大败', 1799), ('之', 1800), ('严严实实', 1801), ('地戴', 1802), ('儿子', 1803), ('浪费时间', 1804), ('隐约', 1805), ('工吧', 1806), ('做出', 1807), ('降降温', 1808), ('收到', 1809), ('许多', 1810), ('留言', 1811), ('无意间', 1812), ('饮用', 1813), ('自来水', 1814), ('一想', 1815), ('遗传', 1816), ('弱', 1817), ('父亲', 1818), ('休业', 1819), ('凶', 1820), ('耷拉', 1821), ('帮助', 1822), ('上课', 1823), ('投入', 1824), ('软件', 1825), ('行', 1826), ('指出', 1827), ('吸着', 1828), ('仿佛', 1829), ('对象', 1830), ('前男友', 1831), ('烧烤', 1832), ('难说', 1833), ('间', 1834), ('深处', 1835), ('会先', 1836), ('不贵', 1837), ('保险', 1838), ('政策', 1839), ('定成', 1840), ('出生', 1841), ('从未', 1842), ('撞车', 1843), ('大胃', 1844), ('王', 1845), ('缓和', 1846), ('一到', 1847), ('我们', 1848), ('高中', 1849), ('试过', 1850), ('翘', 1851), ('掉', 1852), ('放', 1853), ('猪肉', 1854), ('什么样', 1855), ('原稿', 1856), ('毒性', 1857), ('鱼', 1858), ('事儿', 1859), ('揉', 1860), ('无', 1861), ('其他', 1862), ('貌似', 1863), ('吐出来', 1864), ('伴有', 1865), ('说道', 1866), ('祛痰', 1867), ('正', 1868), ('办事', 1869), ('随便', 1870), ('发出', 1871), ('来得', 1872), ('很慢', 1873), ('奴隶', 1874), ('熬过', 1875), ('经历', 1876), ('极了', 1877), ('附带', 1878), ('带血', 1879), ('描述', 1880), ('胸疼', 1881), ('出事', 1882), ('仍然', 1883), ('休学', 1884), ('邻居', 1885), ('太太', 1886), ('英语考试', 1887), ('急忙', 1888), ('冲', 1889), ('进', 1890), ('帮忙', 1891), ('熬', 1892), ('就会', 1893), ('不要紧', 1894), ('利用', 1895), ('科技', 1896), ('转移', 1897), ('别人', 1898), ('技术', 1899), ('尼泊尔人', 1900), ('笔译', 1901), ('翻', 1902), ('遗憾', 1903), ('相当', 1904), ('身上', 1905), ('不太能', 1906), ('发推特', 1907), ('不好意思', 1908), ('如此', 1909), ('因此', 1910), ('估计', 1911), ('古典音乐', 1912), ('故事', 1913), ('感动', 1914), ('测', 1915), ('36', 1916), ('一测', 1917), ('38', 1918), ('强烈', 1919), ('关节痛', 1920), ('乏力感', 1921), ('不同寻常', 1922), ('尴尬', 1923), ('脸', 1924), ('胸部', 1925), ('反应', 1926), ('昏沉', 1927), ('一旦', 1928), ('人开', 1929), ('有救', 1930), ('看见', 1931), ('恐怕', 1932), ('人会', 1933), ('夫妻', 1934), ('久已', 1935), ('趣事', 1936), ('见效', 1937), ('淌', 1938), ('隐隐约约', 1939), ('踢', 1940), ('哈', 1941), ('继续', 1942), ('时得', 1943), ('沥青', 1944), ('放出', 1945), ('很久', 1946), ('烫', 1947), ('时用', 1948), ('遮挡', 1949), ('还好', 1950), ('没事儿', 1951), ('疲乏', 1952), ('洗澡时', 1953), ('过多', 1954), ('美女', 1955), ('生理', 1956), ('烫伤', 1957), ('干不了', 1958), ('国外', 1959), ('传来', 1960), ('打过', 1961), ('大规模', 1962), ('汇总', 1963), ('介绍', 1964), ('依据', 1965), ('最新', 1966), ('科研成果', 1967), ('找', 1968), ('路边', 1969), ('酒', 1970), ('体质', 1971), ('肉松', 1972), ('各', 1973), ('医学', 1974), ('用语', 1975), ('十万火急', 1976), ('信号', 1977), ('这么晚', 1978), ('地面', 1979), ('后天', 1980), ('擅自', 1981), ('自我', 1982), ('判断', 1983), ('之外', 1984), ('如何', 1985), ('之内', 1986), ('打交道', 1987), ('三岁', 1988), ('深奥', 1989), ('易懂', 1990), ('多成', 1991), ('中耳炎', 1992), ('加入', 1993), ('大军', 1994), ('听不懂', 1995), ('遍', 1996), ('外星人', 1997), ('用大', 1998), ('音量', 1999), ('见面', 2000), ('而来', 2001), ('装咳', 2002), ('这边', 2003), ('想来', 2004), ('哪里', 2005), ('正值', 2006), ('高发期', 2007), ('所有', 2008), ('消耗量', 2009), ('传上', 2010), ('增多', 2011), ('有用吗', 2012), ('洗个', 2013), ('得病', 2014), ('想治好', 2015), ('允许', 2016), ('全家', 2017), ('虾', 2018), ('套餐', 2019), ('好吃', 2020), ('完全恢复', 2021), ('欧美', 2022), ('电影', 2023), ('拍', 2024), ('乱七八糟', 2025), ('不禁', 2026), ('忍住', 2027), ('不笑', 2028), ('情绪', 2029), ('热情高涨', 2030), ('下班', 2031), ('早些', 2032), ('先生', 2033), ('壳里', 2034), ('身状', 2035), ('状况', 2036), ('目光', 2037), ('明亮', 2038), ('测体温', 2039), ('上传', 2040), ('田中', 2041), ('几天', 2042), ('不爱', 2043), ('少见', 2044), ('窝', 2045), ('看书', 2046), ('不太', 2047), ('咳多', 2048), ('累头', 2049), ('没好', 2050), ('用量', 2051), ('可真', 2052), ('药对', 2053), ('震惊', 2054), ('多久', 2055), ('牡蛎', 2056), ('早睡', 2057), ('一句', 2058), ('改不了', 2059), ('逞强', 2060), ('夜深', 2061), ('组合拳', 2062), ('植物', 2063), ('十分钟', 2064), ('不怎么样', 2065), ('体乏', 2066), ('坐', 2067), ('止泻药', 2068), ('练出', 2069), ('出疹子', 2070), ('晚安', 2071), ('令人感动', 2072), ('送', 2073), ('特产', 2074), ('摸', 2075), ('着急', 2076), ('受到', 2077), ('影响', 2078), ('全班', 2079), ('停课', 2080), ('情绪高涨', 2081), ('想法', 2082), ('太多手', 2083), ('老是', 2084), ('拖', 2085), ('强健', 2086), ('预定', 2087), ('全体成员', 2088), ('喘', 2089), ('气饭', 2090), ('没味', 2091), ('疲惫不堪', 2092), ('怎么着', 2093), ('强力', 2094), ('呻吟', 2095), ('最烦', 2096), ('打扫', 2097), ('完后', 2098), ('吃治', 2099), ('病痛', 2100), ('小说', 2101), ('几分钟', 2102), ('随身带', 2103), ('不已', 2104), ('治感冒', 2105), ('猪排', 2106), ('很糟', 2107), ('发来', 2108), ('附有', 2109), ('邮件', 2110), ('愉悦', 2111), ('超多', 2112), ('人太吵', 2113), ('流涕', 2114), ('双重', 2115), ('打击', 2116), ('嗓子疼', 2117), ('强打', 2118), ('撑', 2119), ('衣服', 2120), ('杂志', 2121), ('试了试', 2122), ('介意', 2123), ('下去', 2124), ('上司', 2125), ('可恨', 2126), ('途径', 2127), ('只会', 2128), ('不戴', 2129), ('咳来', 2130), ('处方', 2131), ('解脱', 2132), ('嗅觉', 2133), ('烧上来', 2134), ('发达', 2135), ('走', 2136), ('全部', 2137), ('药效', 2138), ('长', 2139), ('犯困', 2140), ('自从', 2141), ('有意识', 2142), ('很流', 2143), ('相同', 2144), ('玩偶', 2145), ('掩盖', 2146), ('拍不进', 2147), ('尚未', 2148), ('错误', 2149), ('紧紧', 2150), ('捆住', 2151), ('病是', 2152), ('烦心', 2153), ('炎热', 2154), ('装有', 2155), ('职员', 2156), ('太过', 2157), ('探望', 2158), ('肚子饿', 2159), ('猛吃', 2160), ('暂且', 2161), ('十年', 2162), ('基本', 2163), ('以往', 2164), ('牛奶', 2165), ('能带', 2166), ('狂笑', 2167), ('疼有', 2168), ('时若', 2169), ('遇到', 2170), ('优美', 2171), ('风景', 2172), ('对话', 2173), ('下毒', 2174), ('不进', 2175), ('引人注意', 2176), ('大妈', 2177), ('肆虐', 2178), ('分辨', 2179), ('后来', 2180), ('悲伤', 2181), ('画面', 2182), ('弄完', 2183), ('心思', 2184), ('肋骨', 2185), ('骨折', 2186), ('预感', 2187), ('太辣', 2188), ('还算轻', 2189), ('没多大', 2190), ('星期一', 2191), ('回复', 2192), ('班里', 2193), ('最先', 2194), ('逃走', 2195), ('回归', 2196), ('费劲', 2197), ('躲', 2198), ('被窝', 2199), ('厌倦', 2200), ('一做', 2201), ('仰卧起坐', 2202), ('一篇', 2203), ('尽量', 2204), ('忍', 2205), ('或者', 2206), ('至少', 2207), ('很闲', 2208), ('算', 2209), ('app', 2210), ('游戏', 2211), ('年龄段', 2212), ('依赖于', 2213), ('很烦', 2214), ('靠', 2215), ('寻访', 2216), ('美食', 2217), ('上学', 2218), ('学习', 2219), ('黄沙', 2220), ('一冷', 2221), ('谈论', 2222), ('得到', 2223), ('果不其然', 2224), ('发烧时', 2225), ('预计', 2226), ('得救', 2227), ('一停', 2228), ('与其说是', 2229), ('不如说', 2230), ('根本就是', 2231), ('夏天', 2232), ('想不起来', 2233), ('耗费', 2234), ('大量', 2235), ('取消', 2236), ('药店', 2237), ('不通', 2238), ('昨夜', 2239), ('晕头晕脑', 2240), ('注意力', 2241), ('集中', 2242), ('鼻血', 2243), ('他人', 2244), ('有着', 2245), ('生理性', 2246), ('另外', 2247), ('工作日程', 2248), ('问问', 2249), ('这种', 2250), ('搞错', 2251), ('名字', 2252), ('失态', 2253), ('它会', 2254), ('向', 2255), ('住院', 2256), ('洗到', 2257), ('止疼药', 2258), ('赖哈', 2259), ('泄露', 2260), ('确认', 2261), ('顺便', 2262), ('良药', 2263), ('100', 2264), ('选', 2265), ('>', 2266), ('中写', 2267), ('放弃', 2268), ('重新', 2269), ('开动', 2270), ('不曾', 2271), ('炎症', 2272), ('有所', 2273), ('痒', 2274), ('异常', 2275), ('地渴', 2276), ('水土不服', 2277), ('每日', 2278), ('做成', 2279), ('此前', 2280), ('有过', 2281), ('有治', 2282), ('不买', 2283), ('西班牙人', 2284), ('开朗', 2285), ('出对', 2286), ('某', 2287), ('不足', 2288), ('坐在', 2289), ('女人', 2290), ('总结', 2291), ('登', 2292)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 30\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "embedding_matrix = np.zeros((vocab_size,EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > vocab_size:\n",
    "        continue\n",
    "    embedding_vector = word_vectors[word]\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 100)           229300    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 28, 128)           38528     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14, 32)            4128      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 3592      \n",
      "=================================================================\n",
      "Total params: 275,548\n",
      "Trainable params: 275,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                     EMBEDDING_DIM,\n",
    "                     mask_zero=False,\n",
    "                     embeddings_initializer=Constant(embedding_matrix),\n",
    "                     input_length=maxlen,\n",
    "                     trainable=True)\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"Influenza\", \"Diarrhea\",\"Hayfever\",\"Cough\",\"Headache\",\"Fever\",\"Runnynose\",\"Cold\"]\n",
    "result_train = train_zh[list_classes].replace({'n':0, 'p':+1})\n",
    "y_train = result_train[list_classes].values\n",
    "\n",
    "result_test = test_zh[list_classes].replace({'n':0, 'p':+1})\n",
    "y_test = result_test[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1919 samples, validate on 640 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.5694 - accuracy: 0.7699 - val_loss: 0.4011 - val_accuracy: 0.8834\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.3849 - accuracy: 0.8754 - val_loss: 0.3692 - val_accuracy: 0.8834\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.3709 - accuracy: 0.8754 - val_loss: 0.3548 - val_accuracy: 0.8834\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.3644 - accuracy: 0.8754 - val_loss: 0.3490 - val_accuracy: 0.8834\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.3592 - accuracy: 0.8754 - val_loss: 0.3464 - val_accuracy: 0.8834\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.3530 - accuracy: 0.8754 - val_loss: 0.3430 - val_accuracy: 0.8834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.3442 - accuracy: 0.8754 - val_loss: 0.3332 - val_accuracy: 0.8834\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.3300 - accuracy: 0.8758 - val_loss: 0.3227 - val_accuracy: 0.8842\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.3063 - accuracy: 0.8794 - val_loss: 0.3015 - val_accuracy: 0.8865\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2693 - accuracy: 0.8913 - val_loss: 0.2693 - val_accuracy: 0.8936\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.2260 - accuracy: 0.9031 - val_loss: 0.2402 - val_accuracy: 0.9016\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1882 - accuracy: 0.9207 - val_loss: 0.2164 - val_accuracy: 0.9135\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1566 - accuracy: 0.9408 - val_loss: 0.2022 - val_accuracy: 0.9219\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1304 - accuracy: 0.9543 - val_loss: 0.1906 - val_accuracy: 0.9248\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1089 - accuracy: 0.9639 - val_loss: 0.1833 - val_accuracy: 0.9303\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0911 - accuracy: 0.9711 - val_loss: 0.1848 - val_accuracy: 0.9322\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0792 - accuracy: 0.9765 - val_loss: 0.1788 - val_accuracy: 0.9363\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0686 - accuracy: 0.9794 - val_loss: 0.1802 - val_accuracy: 0.9379\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0602 - accuracy: 0.9833 - val_loss: 0.1775 - val_accuracy: 0.9410\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0518 - accuracy: 0.9857 - val_loss: 0.1807 - val_accuracy: 0.9428\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0454 - accuracy: 0.9881 - val_loss: 0.1808 - val_accuracy: 0.9424\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0414 - accuracy: 0.9906 - val_loss: 0.1834 - val_accuracy: 0.9449\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0370 - accuracy: 0.9906 - val_loss: 0.1869 - val_accuracy: 0.9432\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0326 - accuracy: 0.9924 - val_loss: 0.1863 - val_accuracy: 0.9443\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0281 - accuracy: 0.9945 - val_loss: 0.1892 - val_accuracy: 0.9457\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=6,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ") # add early stopping\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influenza\n",
      "\n",
      "Test accuracy is 0.9640625\n",
      "Test precision is 0.52\n",
      "Test recall is 0.5416666666666666\n",
      "Test f1-score is 0.5306122448979592\n",
      "\n",
      "Diarrhea\n",
      "\n",
      "Test accuracy is 0.940625\n",
      "Test precision is 0.7321428571428571\n",
      "Test recall is 0.640625\n",
      "Test f1-score is 0.6833333333333332\n",
      "\n",
      "Hayfever\n",
      "\n",
      "Test accuracy is 0.975\n",
      "Test precision is 0.9166666666666666\n",
      "Test recall is 0.717391304347826\n",
      "Test f1-score is 0.8048780487804877\n",
      "\n",
      "Cough\n",
      "\n",
      "Test accuracy is 0.9296875\n",
      "Test precision is 0.8888888888888888\n",
      "Test recall is 0.5\n",
      "Test f1-score is 0.64\n",
      "\n",
      "Headache\n",
      "\n",
      "Test accuracy is 0.9671875\n",
      "Test precision is 0.868421052631579\n",
      "Test recall is 0.8571428571428571\n",
      "Test f1-score is 0.8627450980392157\n",
      "\n",
      "Fever\n",
      "\n",
      "Test accuracy is 0.9125\n",
      "Test precision is 0.7176470588235294\n",
      "Test recall is 0.6559139784946236\n",
      "Test f1-score is 0.6853932584269663\n",
      "\n",
      "Runnynose\n",
      "\n",
      "Test accuracy is 0.9125\n",
      "Test precision is 0.819047619047619\n",
      "Test recall is 0.6991869918699187\n",
      "Test f1-score is 0.7543859649122807\n",
      "\n",
      "Cold\n",
      "\n",
      "Test accuracy is 0.9265625\n",
      "Test precision is 0.864406779661017\n",
      "Test recall is 0.5666666666666667\n",
      "Test f1-score is 0.6845637583892616\n",
      "\n",
      "Summary\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "The average accuracy is 0.9410156249999999\n",
      "The average precision is 0.7909026153577696\n",
      "The average recall is 0.6473241831485699\n",
      "The average f1 score is 0.705738963347438\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "pred_test = model.predict(X_test)\n",
    "classes = pred_test > 0.5\n",
    "pred_test = classes.astype(int) # update predicted value\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# initialize\n",
    "ac = 0 \n",
    "pre = 0\n",
    "rec = 0\n",
    "f1_s = 0\n",
    "\n",
    "for i in range (0,8):\n",
    "    \n",
    "    prediction = pred_test[:, i]\n",
    "    y_sys = y_test[:,i]\n",
    "    print(list_classes[i])\n",
    "    print('\\nTest accuracy is {}'.format(accuracy_score(y_sys, prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(y_sys, prediction, average='binary')))\n",
    "    print('Test recall is {}'.format(recall_score(y_sys, prediction, average='binary')))\n",
    "    print('Test f1-score is {}\\n'.format(f1_score(y_sys, prediction, average='binary')))\n",
    "    \n",
    "    temp_accuracy = accuracy_score(y_sys, prediction)\n",
    "    ac = ac + temp_accuracy\n",
    "    \n",
    "    temp_precision = precision_score(y_sys, prediction, average='binary')\n",
    "    pre = pre + temp_precision\n",
    "    \n",
    "    temp_recall = recall_score(y_sys, prediction, average='binary')\n",
    "    rec = rec + temp_recall\n",
    "    \n",
    "    temp_f1_score = f1_score(y_sys, prediction, average='binary')\n",
    "    f1_s= f1_s + temp_f1_score\n",
    "\n",
    "print(\"Summary\\n>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "ava_accuracy = ac/8\n",
    "print('The average accuracy is {}'.format(ava_accuracy))\n",
    "\n",
    "ava_precision = pre/8\n",
    "print('The average precision is {}'.format(ava_precision))\n",
    "\n",
    "ava_recall = rec/8\n",
    "print('The average recall is {}'.format(ava_recall))\n",
    "\n",
    "ava_f1_score = f1_s/8\n",
    "print('The average f1 score is {}'.format(ava_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label='Test accuracy')\n",
    "    plt.title('Training and testing accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Test loss')\n",
    "    plt.title('Training and testing loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(\"CNN_Chi.jpg\")\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_ja = pd.read_csv(\"NTCIR-13_MedWeb_ja_training.csv\", na_values='NaN',keep_default_na=False)\n",
    "test_ja = pd.read_csv(\"NTCIR-13_MedWeb_ja_test.csv\", na_values='NaN',keep_default_na=False)\n",
    "test_ja = test_ja[:640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation inside\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "\n",
    "def clean_text_ja(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem:re.sub(r'[{}]+'.format(punctuation),'',elem))\n",
    "    return df\n",
    "\n",
    "# update \n",
    "train_ja = clean_text_ja(train_ja,\"Tweet\")\n",
    "test_ja = clean_text_ja(test_ja,\"Tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Japanese tokenizer\n",
    "import nagisa\n",
    "\n",
    "def tokenize_jp(doc):\n",
    "    doc = nagisa.tagging(doc)\n",
    "    return doc.words\n",
    "\n",
    "tweet_train_ja = [list(tokenize_jp(i)) for i in train_ja.Tweet]\n",
    "tweet_test_ja = [list(tokenize_jp(i)) for i in test_ja.Tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "collected 2161 word types from a corpus of 23974 raw words and 1920 sentences\n",
      "Loading a fresh vocabulary\n",
      "effective_min_count=1 retains 2161 unique words (100% of original 2161, drops 0)\n",
      "effective_min_count=1 leaves 23974 word corpus (100% of original 23974, drops 0)\n",
      "deleting the raw counts dictionary of 2161 items\n",
      "sample=0.001 downsamples 51 most-common words\n",
      "downsampling leaves estimated 14748 word corpus (61.5% of prior 23974)\n",
      "estimated required memory for 2161 words and 100 dimensions: 2809300 bytes\n",
      "resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build word2vec model using Gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model with 3 workers on 2161 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 1 : training on 23974 raw words (14696 effective words) took 0.1s, 100713 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 2 : training on 23974 raw words (14828 effective words) took 0.1s, 134034 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 3 : training on 23974 raw words (14699 effective words) took 0.1s, 137377 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 4 : training on 23974 raw words (14778 effective words) took 0.1s, 118769 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 5 : training on 23974 raw words (14761 effective words) took 0.1s, 149068 effective words/s\n",
      "training on a 119870 raw words (73762 effective words) took 0.7s, 113215 effective words/s\n",
      "under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word vectors: 2161\n"
     ]
    }
   ],
   "source": [
    "print('Build word2vec model using Gensim')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tweet_train_ja, size=100, window=5, min_count=1, workers=3, sg=1, negative=15)\n",
    "word_vectors = model.wv\n",
    "print(\"Number of word vectors: {}\".format(len(word_vectors.vocab)))\n",
    "\n",
    "# print(model['全身'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('vectorvisualjp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load gensim word2vec\n",
    "w2v_path = 'vectorvisualjp'\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_path)\n",
    "\n",
    "import io\n",
    "\n",
    "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
    "\"\"\"\n",
    "0.1\\t0.2\\t0.5\\t0.9\n",
    "0.2\\t0.1\\t5.0\\t0.2\n",
    "0.4\\t0.1\\t7.0\\t0.8\n",
    "\"\"\"\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Meta data file, `\\n` seperated word\n",
    "\"\"\"\n",
    "token1\n",
    "token2\n",
    "token3\n",
    "\"\"\"\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Write meta file and vector file\n",
    "for index in range(len(w2v.index2word)):\n",
    "    word = w2v.index2word[index]\n",
    "    vec = w2v.vectors[index]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweet_train_ja)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(tweet_train_ja)\n",
    "X_test = tokenizer.texts_to_sequences(tweet_test_ja)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('が', 1), ('て', 2), ('の', 3), ('た', 4), ('に', 5), ('で', 6), ('だ', 7), ('し', 8), ('は', 9), ('と', 10), ('を', 11), ('か', 12), ('も', 13), ('風邪', 14), ('ない', 15), ('から', 16), ('頭痛', 17), ('花粉', 18), ('症', 19), ('な', 20), ('熱', 21), ('下痢', 22), ('・', 23), ('けど', 24), ('よ', 25), ('ん', 26), ('って', 27), ('する', 28), ('咳', 29), ('鼻水', 30), ('なっ', 31), ('てる', 32), ('インフル', 33), ('たら', 34), ('やばい', 35), ('インフルエンザ', 36), ('今日', 37), ('き', 38), ('ある', 39), ('らしい', 40), ('出', 41), ('薬', 42), ('ね', 43), ('鼻づまり', 44), ('いる', 45), ('朝', 46), ('仕事', 47), ('痛い', 48), ('対策', 49), ('止まら', 50), ('わ', 51), ('ひどい', 52), ('すぎ', 53), ('お腹', 54), ('痰', 55), ('こと', 56), ('なる', 57), ('休む', 58), ('い', 59), ('まさか', 60), ('季節', 61), ('れ', 62), ('思っ', 63), ('人', 64), ('頭', 65), ('最悪', 66), ('ひい', 67), ('だるい', 68), ('っぽい', 69), ('なく', 70), ('なん', 71), ('だっ', 72), ('とき', 73), ('まだ', 74), ('さ', 75), ('久し', 76), ('感染', 77), ('鼻', 78), ('この', 79), ('かかっ', 80), ('最近', 81), ('鳥', 82), ('出る', 83), ('ワクチン', 84), ('お', 85), ('エチケット', 86), ('です', 87), ('何', 88), ('飲ん', 89), ('ます', 90), ('そう', 91), ('的', 92), ('早く', 93), ('寒気', 94), ('腹筋', 95), ('兄', 96), ('よう', 97), ('みたい', 98), ('いい', 99), ('症状', 100), ('振り', 101), ('行っ', 102), ('ブログ', 103), ('中', 104), ('せい', 105), ('今年', 106), ('しまっ', 107), ('つらい', 108), ('大変', 109), ('犬', 110), ('微妙', 111), ('微熱', 112), ('わざと', 113), ('引い', 114), ('たい', 115), ('言っ', 116), ('病院', 117), ('痛く', 118), ('でき', 119), ('高熱', 120), ('なんて', 121), ('こんな', 122), ('効果', 123), ('英語', 124), ('スペイン', 125), ('なかっ', 126), ('部活', 127), ('どう', 128), ('娘', 129), ('東京', 130), ('だけ', 131), ('病気', 132), ('これ', 133), ('や', 134), ('おたふく', 135), ('じゃ', 136), ('来春', 137), ('解消', 138), ('いう', 139), ('疲れる', 140), ('一', 141), ('必要', 142), ('リンパ', 143), ('やっ', 144), ('外出', 145), ('誰', 146), ('止まる', 147), ('ニュース', 148), ('無理', 149), ('見', 150), ('気', 151), ('くらい', 152), ('きつい', 153), ('今', 154), ('本格', 155), ('もう', 156), ('出し', 157), ('ひどく', 158), ('私', 159), ('ば', 160), ('昨日', 161), ('テレビ', 162), ('激しい', 163), ('携帯', 164), ('さん', 165), ('寝る', 166), ('流行っ', 167), ('集団', 168), ('日', 169), ('苦痛', 170), ('回復', 171), ('なあ', 172), ('ずっと', 173), ('でる', 174), ('ぼーっ', 175), ('ず', 176), ('なら', 177), ('マスク', 178), ('起き', 179), ('学校', 180), ('ところ', 181), ('ネパール', 182), ('少ない', 183), ('ちゃっ', 184), ('だろう', 185), ('風呂', 186), ('行く', 187), ('明日', 188), ('だら', 189), ('俺', 190), ('寒い', 191), ('本当', 192), ('翻訳', 193), ('まで', 194), ('帰宅', 195), ('教え', 196), ('すぎる', 197), ('体調', 198), ('腫れ', 199), ('休み', 200), ('ー', 201), ('ため', 202), ('解熱', 203), ('時', 204), ('妻', 205), ('らしく', 206), ('よー', 207), ('嬉しい', 208), ('ちょっと', 209), ('気味', 210), ('相手', 211), ('自分', 212), ('言う', 213), ('食べ', 214), ('体', 215), ('昨晩', 216), ('ぼーっと', 217), ('眠い', 218), ('抑える', 219), ('しれ', 220), ('剤', 221), ('いつ', 222), ('アトピー', 223), ('中国', 224), ('開発', 225), ('れる', 226), ('まし', 227), ('休ん', 228), ('再発', 229), ('しよう', 230), ('来', 231), ('なきゃ', 232), ('喉', 233), ('もらっ', 234), ('言わ', 235), ('休める', 236), ('契約', 237), ('かかる', 238), ('なー', 239), ('前', 240), ('あっ', 241), ('られ', 242), ('患者', 243), ('帰っ', 244), ('嫁', 245), ('写真', 246), ('ほしい', 247), ('弟', 248), ('大事', 249), ('秋', 250), ('サッカー', 251), ('だー', 252), ('処方', 253), ('思う', 254), ('くる', 255), ('会社', 256), ('大好き', 257), ('治っ', 258), ('くれ', 259), ('辛い', 260), ('科学', 261), ('起きる', 262), ('祖母', 263), ('爆笑', 264), ('怖い', 265), ('旅行', 266), ('だろ', 267), ('ひど', 268), ('思わ', 269), ('強い', 270), ('時間', 271), ('女性', 272), ('効く', 273), ('もの', 274), ('ませ', 275), ('多い', 276), ('続い', 277), ('問題', 278), ('しか', 279), ('ぜ', 280), ('打っ', 281), ('やつ', 282), ('家', 283), ('帰る', 284), ('涼しい', 285), ('検査', 286), ('やすい', 287), ('思い出す', 288), ('手洗い', 289), ('巫女', 290), ('マジ', 291), ('鼻風', 292), ('うち', 293), ('手', 294), ('流行', 295), ('下がっ', 296), ('ちゃ', 297), ('宇宙', 298), ('飲む', 299), ('よく', 300), ('ただ', 301), ('危機', 302), ('弁当', 303), ('また', 304), ('あり', 305), ('軽い', 306), ('やっと', 307), ('めっちゃ', 308), ('思い出し', 309), ('すごく', 310), ('そろそろ', 311), ('以外', 312), ('管理', 313), ('完璧', 314), ('咳し', 315), ('聞い', 316), ('トイレ', 317), ('君', 318), ('ゆとり', 319), ('知ら', 320), ('休め', 321), ('いか', 322), ('入っ', 323), ('電車', 324), ('せ', 325), ('寝', 326), ('ぶり', 327), ('混じる', 328), ('っけ', 329), ('しだるい', 330), ('なぁ', 331), ('治ら', 332), ('すごい', 333), ('参っ', 334), ('治まっ', 335), ('丼', 336), ('邪', 337), ('行ける', 338), ('謎', 339), ('聴く', 340), ('行き', 341), ('音楽', 342), ('気配', 343), ('目', 344), ('大人', 345), ('たふく', 346), ('使う', 347), ('口', 348), ('背中', 349), ('遂に', 350), ('装着', 351), ('たく', 352), ('戯れる', 353), ('読ん', 354), ('予防', 355), ('食', 356), ('中毒', 357), ('下がら', 358), ('3', 359), ('早め', 360), ('行か', 361), ('療法', 362), ('あの', 363), ('ちゃんと', 364), ('全然', 365), ('方', 366), ('一番', 367), ('胸', 368), ('友達', 369), ('度', 370), ('熱出', 371), ('やら', 372), ('何時', 373), ('流行る', 374), ('法', 375), ('だるく', 376), ('血', 377), ('方法', 378), ('よかっ', 379), ('み', 380), ('原因', 381), ('腫れる', 382), ('水', 383), ('具合', 384), ('風邪薬', 385), ('すぐ', 386), ('注射', 387), ('量', 388), ('時期', 389), ('握手', 390), ('行こう', 391), ('悩まさ', 392), ('うがい', 393), ('助け', 394), ('出す', 395), ('わけ', 396), ('みんな', 397), ('悪い', 398), ('完全', 399), ('話', 400), ('早退', 401), ('元気', 402), ('痛み', 403), ('感じ', 404), ('続く', 405), ('発症', 406), ('ください', 407), ('ちゃん', 408), ('いけ', 409), ('毎年', 410), ('バイト', 411), ('ソロソロ', 412), ('診断', 413), ('より', 414), ('さっき', 415), ('本', 416), ('止まっ', 417), ('持っ', 418), ('大丈夫', 419), ('治る', 420), ('なし', 421), ('副', 422), ('ねぇ', 423), ('笑う', 424), ('種', 425), ('高い', 426), ('わから', 427), ('買っ', 428), ('まじ', 429), ('変わり目', 430), ('体液', 431), ('腹', 432), ('つけ', 433), ('へ', 434), ('なんか', 435), ('なり', 436), ('酷い', 437), ('疲れ', 438), ('眠れ', 439), ('過ぎ', 440), ('しっかり', 441), ('痛む', 442), ('檜', 443), ('事', 444), ('先', 445), ('不安', 446), ('こそ', 447), ('忘れ', 448), ('週間', 449), ('しまう', 450), ('ねー', 451), ('作っ', 452), ('心配', 453), ('ほう', 454), ('どこ', 455), ('つら', 456), ('違う', 457), ('さっさと', 458), ('力', 459), ('べき', 460), ('手術', 461), ('医者', 462), ('勘弁', 463), ('急', 464), ('涼しく', 465), ('身体', 466), ('入ら', 467), ('子', 468), ('つい', 469), ('書い', 470), ('ようやく', 471), ('ぞ', 472), ('もっ', 473), ('日本', 474), ('絶対', 475), ('姿', 476), ('たくさん', 477), ('ウイルス', 478), ('あまり', 479), ('眠く', 480), ('テスト', 481), ('どれ', 482), ('良い', 483), ('効か', 484), ('やばく', 485), ('調子', 486), ('以上', 487), ('楽', 488), ('接種', 489), ('できる', 490), ('隣', 491), ('行け', 492), ('去年', 493), ('シーン', 494), ('読む', 495), ('それ', 496), ('渇く', 497), ('寝込ん', 498), ('とまら', 499), ('皆', 500), ('土産', 501), ('知っ', 502), ('会議', 503), ('0', 504), ('どんな', 505), ('混じっ', 506), ('1', 507), ('作用', 508), ('昔', 509), ('体力', 510), ('僕', 511), ('悪く', 512), ('治す', 513), ('タイミング', 514), ('増え', 515), ('今回', 516), ('ティッシュ', 517), ('考える', 518), ('割れ', 519), ('垂れ', 520), ('年', 521), ('知り', 522), ('だし', 523), ('ケース', 524), ('風', 525), ('いっ', 526), ('いくら', 527), ('る', 528), ('笑っ', 529), ('なけれ', 530), ('その', 531), ('大', 532), ('だれ', 533), ('いま', 534), ('やば', 535), ('毎日', 536), ('欲しい', 537), ('あと', 538), ('取ら', 539), ('びっくり', 540), ('咳止め', 541), ('熱い', 542), ('予定', 543), ('くしゃみ', 544), ('軽く', 545), ('過ぎる', 546), ('頑張っ', 547), ('沢山', 548), ('毒', 549), ('奴', 550), ('発達', 551), ('ヘッド', 552), ('御座る', 553), ('医師', 554), ('打た', 555), ('ダメ', 556), ('きつく', 557), ('いく', 558), ('吹く', 559), ('アレルギー', 560), ('ちゃう', 561), ('インフルエンザワクチン', 562), ('案の定', 563), ('デング', 564), ('今朝', 565), ('間違える', 566), ('あんな', 567), ('見る', 568), ('絶賛', 569), ('作業', 570), ('特に', 571), ('吐い', 572), ('テンション', 573), ('っぽく', 574), ('彼', 575), ('こりゃ', 576), ('引く', 577), ('わー', 578), ('来る', 579), ('重症', 580), ('咳込み', 581), ('打ち', 582), ('苦しん', 583), ('通じ', 584), ('飲み', 585), ('事故', 586), ('よる', 587), ('大分', 588), ('ねえ', 589), ('間', 590), ('使わ', 591), ('やっぱり', 592), ('いきなり', 593), ('家族', 594), ('最初', 595), ('くれー', 596), ('体制', 597), ('御', 598), ('粗末', 599), ('ほど', 600), ('場所', 601), ('少し', 602), ('あれ', 603), ('聞く', 604), ('やばし', 605), ('激しく', 606), ('万', 607), ('腺', 608), ('集中', 609), ('ホント', 610), ('アップ', 611), ('のど', 612), ('電話', 613), ('ここ', 614), ('どっち', 615), ('すれ', 616), ('どの', 617), ('治まる', 618), ('者', 619), ('格闘', 620), ('死ん', 621), ('けれど', 622), ('まら', 623), ('寒く', 624), ('子供', 625), ('頃', 626), ('猛威', 627), ('奮っ', 628), ('治療', 629), ('でし', 630), ('でしょう', 631), ('冷え', 632), ('そして', 633), ('頭痛い', 634), ('どうぞ', 635), ('ヨーグルト', 636), ('対処', 637), ('止ん', 638), ('ゆっくり', 639), ('上がる', 640), ('多く', 641), ('飲もう', 642), ('春', 643), ('やめ', 644), ('超', 645), ('せっかく', 646), ('みる', 647), ('ごめん', 648), ('顔', 649), ('気持ち', 650), ('イライラ', 651), ('垂らし', 652), ('状態', 653), ('着信', 654), ('茶', 655), ('帰り', 656), ('言い', 657), ('我が家', 658), ('聴い', 659), ('今度', 660), ('生', 661), ('入る', 662), ('寝よう', 663), ('大会', 664), ('同じ', 665), ('厚労', 666), ('経っ', 667), ('普通', 668), ('憂鬱', 669), ('ついに', 670), ('なかなか', 671), ('治まら', 672), ('外', 673), ('しんどい', 674), ('奥', 675), ('すべて', 676), ('結構', 677), ('一瞬', 678), ('内', 679), ('休ま', 680), ('ひどかっ', 681), ('更新', 682), ('だいぶ', 683), ('大切', 684), ('食う', 685), ('だる', 686), ('違い', 687), ('嫌', 688), ('始め', 689), ('親子', 690), ('とっ', 691), ('蔓延', 692), ('中止', 693), ('声', 694), ('遅い', 695), ('わたし', 696), ('母', 697), ('止め', 698), ('よい', 699), ('むしろ', 700), ('はかっ', 701), ('試し', 702), ('初期', 703), ('多', 704), ('頑張ろう', 705), ('気分', 706), ('デビュー', 707), ('かなり', 708), ('上がっ', 709), ('酷', 710), ('鼻かみ', 711), ('なさ', 712), ('関係', 713), ('つ', 714), ('試合', 715), ('観戦', 716), ('ひいたー', 717), ('息', 718), ('苦しい', 719), ('計っ', 720), ('回', 721), ('原発', 722), ('復帰', 723), ('飲め', 724), ('頼っ', 725), ('焦っ', 726), ('咳止まら', 727), ('情報', 728), ('状況', 729), ('食べ物', 730), ('耳鼻', 731), ('科', 732), ('鼻腔', 733), ('炎', 734), ('全く', 735), ('置く', 736), ('アイドル', 737), ('会', 738), ('死に', 739), ('赤ちゃん', 740), ('戯れ', 741), ('パソコン', 742), ('使い', 743), ('メガネ', 744), ('まま', 745), ('でしょ', 746), ('パターン', 747), ('休', 748), ('ヘルメット', 749), ('数', 750), ('控え', 751), ('忙しい', 752), ('蜂', 753), ('訳', 754), ('帰ろう', 755), ('出来', 756), ('少なく', 757), ('名前', 758), ('無い', 759), ('受け', 760), ('解決', 761), ('くれる', 762), ('記事', 763), ('全員', 764), ('ピー', 765), ('見通し', 766), ('書く', 767), ('ながら', 768), ('ひか', 769), ('はじめ', 770), ('エアコン', 771), ('料理', 772), ('生活', 773), ('感', 774), ('発熱', 775), ('小さい', 776), ('食べる', 777), ('外れ', 778), ('特効', 779), ('関節', 780), ('とりあえず', 781), ('色々', 782), ('化', 783), ('はず', 784), ('分から', 785), ('伝え', 786), ('困っ', 787), ('てん', 788), ('家事', 789), ('マッサージ', 790), ('ほとんど', 791), ('遊び', 792), ('鼻風邪', 793), ('もちろん', 794), ('多少', 795), ('定期', 796), ('店', 797), ('いろいろ', 798), ('出さ', 799), ('べし', 800), ('笑え', 801), ('出社', 802), ('ぐらい', 803), ('おかげ', 804), ('休もう', 805), ('歳', 806), ('すら', 807), ('咳払い', 808), ('プレゼン', 809), ('かかり', 810), ('性', 811), ('よっ', 812), ('抑え', 813), ('いっぱい', 814), ('不足', 815), ('笑', 816), ('漏れ', 817), ('人前', 818), ('たー', 819), ('ネット', 820), ('暇', 821), ('看病', 822), ('嘔吐', 823), ('受ける', 824), ('っと', 825), ('やがっ', 826), ('うつさ', 827), ('戻っ', 828), ('下手', 829), ('歌', 830), ('禁止', 831), ('筋肉', 832), ('痛', 833), ('ホン', 834), ('始める', 835), ('眠れる', 836), ('途中', 837), ('きつ', 838), ('まるで', 839), ('おさえる', 840), ('園', 841), ('証拠', 842), ('てっ', 843), ('神社', 844), ('ストレス', 845), ('戦', 846), ('うるさい', 847), ('入れ', 848), ('初', 849), ('なーい', 850), ('首', 851), ('2', 852), ('なに', 853), ('死ぬ', 854), ('社会', 855), ('省', 856), ('正直', 857), ('布団', 858), ('ばい', 859), ('下がり', 860), ('牛丼', 861), ('鍛え', 862), ('三', 863), ('診', 864), ('え', 865), ('あたっ', 866), ('強く', 867), ('いただき', 868), ('怖', 869), ('安く', 870), ('調べる', 871), ('めんどう', 872), ('好き', 873), ('咳する', 874), ('昨夜', 875), ('選手', 876), ('受験', 877), ('仲間', 878), ('入り', 879), ('天気', 880), ('処分', 881), ('ちまっ', 882), ('思い', 883), ('リラックス', 884), ('ごはん', 885), ('周り', 886), ('眼鏡', 887), ('ばかり', 888), ('言葉', 889), ('用語', 890), ('やり', 891), ('入れる', 892), ('書', 893), ('治りかけ', 894), ('週末', 895), ('すみ', 896), ('授業', 897), ('参る', 898), ('部屋', 899), ('冬', 900), ('移る', 901), ('悪かっ', 902), ('面接', 903), ('例年', 904), ('タイプ', 905), ('もらえ', 906), ('はれ', 907), ('海外', 908), ('帰ら', 909), ('普段', 910), ('まず', 911), ('おく', 912), ('セット', 913), ('上', 914), ('襲わ', 915), ('しょう', 916), ('続き', 917), ('作る', 918), ('しさっき', 919), ('こ', 920), ('フォロワー', 921), ('難しい', 922), ('デート', 923), ('考え', 924), ('止める', 925), ('しぼーっと', 926), ('途端', 927), ('言え', 928), ('痛かっ', 929), ('めちゃくちゃ', 930), ('飲ま', 931), ('とる', 932), ('上司', 933), ('ぱん', 934), ('一向', 935), ('下がる', 936), ('再開', 937), ('押さえる', 938), ('晩', 939), ('腹痛', 940), ('起こし', 941), ('道端', 942), ('持ち', 943), ('余っ', 944), ('相', 945), ('変わら', 946), ('繰り返し', 947), ('鼻血', 948), ('たかっ', 949), ('会え', 950), ('涙', 951), ('事件', 952), ('負け', 953), ('うなされ', 954), ('直前', 955), ('4', 956), ('未だ', 957), ('間違い', 958), ('困る', 959), ('逆', 960), ('あんまり', 961), ('わかっ', 962), ('ほんと', 963), ('今夜', 964), ('やめよう', 965), ('試験', 966), ('打つ', 967), ('かー', 968), ('もち', 969), ('だめ', 970), ('せる', 971), ('笑い', 972), ('うるさ', 973), ('アプリ', 974), ('しまい', 975), ('すっかり', 976), ('所', 977), ('なぜ', 978), ('全部', 979), ('平気', 980), ('長引く', 981), ('さすが', 982), ('変', 983), ('辛', 984), ('様', 985), ('感動', 986), ('もん', 987), ('辺り', 988), ('しぼーっ', 989), ('助かる', 990), ('吹い', 991), ('夜', 992), ('生理', 993), ('まとめ', 994), ('もし', 995), ('いら', 996), ('やばかっ', 997), ('持ち歩い', 998), ('限っ', 999), ('載っ', 1000), ('酷く', 1001), ('キツイ', 1002), ('やたら', 1003), ('ええ', 1004), ('ダブル', 1005), ('パンチ', 1006), ('つもり', 1007), ('分', 1008), ('咳痰', 1009), ('世代', 1010), ('貰っ', 1011), ('絡む', 1012), ('旅先', 1013), ('散歩', 1014), ('おもっ', 1015), ('全身', 1016), ('おさまる', 1017), ('際', 1018), ('あかん', 1019), ('んかっ', 1020), ('りっぱ', 1021), ('間中', 1022), ('知り合っ', 1023), ('侮れ', 1024), ('二', 1025), ('放射', 1026), ('能', 1027), ('落ち', 1028), ('襲っ', 1029), ('上手く', 1030), ('止まん', 1031), ('良く', 1032), ('重なっ', 1033), ('免疫', 1034), ('出来る', 1035), ('めっちゃきく', 1036), ('薬誰', 1037), ('つくっ', 1038), ('守ら', 1039), ('乗んな', 1040), ('もったい', 1041), ('思い込ん', 1042), ('悪化', 1043), ('苦し', 1044), ('出かけ', 1045), ('寄り道', 1046), ('ビビる', 1047), ('とこ', 1048), ('うーんこ', 1049), ('担任', 1050), ('指数', 1051), ('関数', 1052), ('つらかっ', 1053), ('柔らかい', 1054), ('断ら', 1055), ('国内', 1056), ('整っ', 1057), ('容器', 1058), ('凄く', 1059), ('ほっ', 1060), ('ほか', 1061), ('冷ます', 1062), ('崩し', 1063), ('温床', 1064), ('一部', 1065), ('悪夢', 1066), ('ぼんやり', 1067), ('鼻炎', 1068), ('力強い', 1069), ('コーヒー', 1070), ('大きな', 1071), ('音', 1072), ('確信', 1073), ('たえ', 1074), ('じゃっ', 1075), ('覚める', 1076), ('ヤバイ', 1077), ('洗浄', 1078), ('試す', 1079), ('勇気', 1080), ('いろんな', 1081), ('触る', 1082), ('コスパ', 1083), ('つり', 1084), ('まっ', 1085), ('調べ', 1086), ('まん', 1087), ('速攻', 1088), ('風っぴき', 1089), ('万全', 1090), ('驚い', 1091), ('突然', 1092), ('めちゃ', 1093), ('がんばれ', 1094), ('連絡', 1095), ('手当てる', 1096), ('パフォーマンス', 1097), ('おれ', 1098), ('さま', 1099), ('撮っ', 1100), ('ヤバく', 1101), ('絡まっ', 1102), ('兼ね', 1103), ('飛ん', 1104), ('疱瘡', 1105), ('内科', 1106), ('院内', 1107), ('同様', 1108), ('アイテム', 1109), ('しらす', 1110), ('働い', 1111), ('遊園', 1112), ('地', 1113), ('書け', 1114), ('自動', 1115), ('車', 1116), ('排出', 1117), ('暑', 1118), ('助長', 1119), ('後', 1120), ('洗わ', 1121), ('以降', 1122), ('分かっ', 1123), ('やばいっ', 1124), ('出かける', 1125), ('増える', 1126), ('月', 1127), ('痛ま', 1128), ('危ない', 1129), ('きれい', 1130), ('おとなしく', 1131), ('死亡', 1132), ('覚える', 1133), ('付けよう', 1134), ('絶滅', 1135), ('ひどいぼーっと', 1136), ('他', 1137), ('とい', 1138), ('こども', 1139), ('実家', 1140), ('送ら', 1141), ('愛犬', 1142), ('すっきり', 1143), ('嬉しかっ', 1144), ('トマト', 1145), ('せき', 1146), ('進歩', 1147), ('薬品', 1148), ('世の中', 1149), ('種類', 1150), ('個々', 1151), ('研究', 1152), ('進ん', 1153), ('治れ', 1154), ('赤', 1155), ('まずい', 1156), ('高齢', 1157), ('まずく', 1158), ('小', 1159), ('喉乾く', 1160), ('始末', 1161), ('新型', 1162), ('筈', 1163), ('キット', 1164), ('割', 1165), ('わかん', 1166), ('家政', 1167), ('婦', 1168), ('業務', 1169), ('頼ま', 1170), ('対し', 1171), ('無さ', 1172), ('慌て', 1173), ('同時', 1174), ('ハンパ', 1175), ('壊し', 1176), ('愛', 1177), ('冷める', 1178), ('生姜', 1179), ('湯', 1180), ('いれ', 1181), ('スギ', 1182), ('思いやら', 1183), ('うつら', 1184), ('楽しかっ', 1185), ('風呂入っ', 1186), ('やばそう', 1187), ('見つけ', 1188), ('ご', 1189), ('存知', 1190), ('頂け', 1191), ('ばい止まる', 1192), ('寝れ', 1193), ('証明', 1194), ('しまだ', 1195), ('重度', 1196), ('増減', 1197), ('たいして', 1198), ('意味', 1199), ('向かう', 1200), ('とんだ', 1201), ('暴走', 1202), ('常備', 1203), ('忙しく', 1204), ('治まり', 1205), ('なくっ', 1206), ('混ざっ', 1207), ('直し', 1208), ('毒素', 1209), ('かから', 1210), ('完治', 1211), ('戦い', 1212), ('始まる', 1213), ('久々', 1214), ('しもう', 1215), ('乾く', 1216), ('話ほん', 1217), ('惰性', 1218), ('済ん', 1219), ('ヒューヒュー', 1220), ('がんばっ', 1221), ('知れ', 1222), ('決行', 1223), ('つけよ', 1224), ('絡ん', 1225), ('ただるい', 1226), ('由来', 1227), ('からん', 1228), ('単位', 1229), ('やすさっ', 1230), ('ちがう', 1231), ('陣', 1232), ('罹患', 1233), ('嫌い', 1234), ('こよう', 1235), ('やばり', 1236), ('おさまっ', 1237), ('取れ', 1238), ('くだる', 1239), ('一生', 1240), ('懸命', 1241), ('素質', 1242), ('はかどら', 1243), ('ござる', 1244), ('練習', 1245), ('難しく', 1246), ('かけこん', 1247), ('引き', 1248), ('崩す', 1249), ('まい', 1250), ('たべ', 1251), ('先生', 1252), ('守ろう', 1253), ('舞台', 1254), ('ウィッグ', 1255), ('被る', 1256), ('想像', 1257), ('つきっきり', 1258), ('よいや', 1259), ('薬使う', 1260), ('とまり', 1261), ('しんど', 1262), ('あげ', 1263), ('みれ', 1264), ('同僚', 1265), ('めわざと', 1266), ('楽しめ', 1267), ('耳', 1268), ('曲がる', 1269), ('わきつく', 1270), ('っつー', 1271), ('載せ', 1272), ('終わる', 1273), ('いたわり', 1274), ('なきゃー', 1275), ('総じて', 1276), ('併発', 1277), ('苦しかっ', 1278), ('可愛い', 1279), ('なくなら', 1280), ('打', 1281), ('膿状', 1282), ('ずーっと', 1283), ('告白', 1284), ('決め', 1285), ('叫び', 1286), ('満点', 1287), ('どっと', 1288), ('恐ろし', 1289), ('昆布', 1290), ('弱く', 1291), ('欠かさ', 1292), ('過ごせ', 1293), ('なめる', 1294), ('今月', 1295), ('ほん', 1296), ('交信', 1297), ('生徒', 1298), ('保育', 1299), ('生き', 1300), ('降り', 1301), ('真夏', 1302), ('ファンタジー', 1303), ('無く', 1304), ('入ん', 1305), ('にくい', 1306), ('腫れ上がっ', 1307), ('とにかく', 1308), ('付け', 1309), ('こわい', 1310), ('アルバイト', 1311), ('募集', 1312), ('応募', 1313), ('養生', 1314), ('インフルエンザマジ', 1315), ('決勝', 1316), ('画期', 1317), ('浪費', 1318), ('先週', 1319), ('コンサート', 1320), ('飛散', 1321), ('来日', 1322), ('準備', 1323), ('やつっ', 1324), ('ごまかす', 1325), ('拭く', 1326), ('小学', 1327), ('保健', 1328), ('室', 1329), ('おなら', 1330), ('漏らし', 1331), ('犬預かる', 1332), ('つけよう', 1333), ('翌日', 1334), ('人生', 1335), ('頭痛く', 1336), ('遅れ', 1337), ('来週', 1338), ('祈る', 1339), ('脳', 1340), ('みそ', 1341), ('流出', 1342), ('世間', 1343), ('一緒', 1344), ('予想', 1345), ('株', 1346), ('作ら', 1347), ('ライブ', 1348), ('邪か', 1349), ('限る', 1350), ('急ぎ', 1351), ('舞い込み', 1352), ('土日', 1353), ('つぶれ', 1354), ('レポート', 1355), ('提出', 1356), ('取り除く', 1357), ('放出', 1358), ('錯覚', 1359), ('空港', 1360), ('搬送', 1361), ('例', 1362), ('発表', 1363), ('咳き込ん', 1364), ('壊', 1365), ('言おう', 1366), ('関する', 1367), ('ツイッター', 1368), ('発信', 1369), ('電波', 1370), ('受信', 1371), ('下がらん', 1372), ('立ち', 1373), ('やっぱ', 1374), ('不', 1375), ('衛生', 1376), ('安い', 1377), ('屋', 1378), ('薄着', 1379), ('センパイ', 1380), ('着る', 1381), ('上着', 1382), ('渡さ', 1383), ('優しい', 1384), ('幸せ', 1385), ('発音', 1386), ('瞬間', 1387), ('オール', 1388), ('スター', 1389), ('寝苦しい', 1390), ('ぎみ', 1391), ('さひょっとこ', 1392), ('矢先', 1393), ('食っ', 1394), ('ぽい', 1395), ('充血', 1396), ('ひかえ', 1397), ('バッテリー', 1398), ('広がっ', 1399), ('とうとう', 1400), ('汚', 1401), ('しばらく', 1402), ('倒れる', 1403), ('頭ぼーっ', 1404), ('あたり', 1405), ('すま', 1406), ('くさい', 1407), ('説明', 1408), ('根源', 1409), ('抹殺', 1410), ('ダウン', 1411), ('横', 1412), ('かゆ', 1413), ('柄', 1414), ('ぜんぜん', 1415), ('9', 1416), ('しゃい', 1417), ('信じ', 1418), ('素早く', 1419), ('下げる', 1420), ('半身', 1421), ('浴', 1422), ('加え', 1423), ('無能', 1424), ('ばっか', 1425), ('疑い', 1426), ('アヒル', 1427), ('ニワトリ', 1428), ('羽', 1429), ('頼むー', 1430), ('停止', 1431), ('馳せ', 1432), ('天体', 1433), ('観測', 1434), ('など', 1435), ('ホットレモン', 1436), ('ましょ', 1437), ('ノロウイルス', 1438), ('起朝', 1439), ('徹底', 1440), ('流れ', 1441), ('発明', 1442), ('噂', 1443), ('うつるん', 1444), ('ノンストップ', 1445), ('どんどん', 1446), ('辞書', 1447), ('風呂やめ', 1448), ('こう', 1449), ('リアル', 1450), ('むかつく', 1451), ('おた', 1452), ('ふくだっ', 1453), ('おさえ', 1454), ('地味', 1455), ('吐き', 1456), ('ひきつっ', 1457), ('観察', 1458), ('こらえ', 1459), ('今頃', 1460), ('ころ', 1461), ('下', 1462), ('ひとり', 1463), ('新た', 1464), ('注目', 1465), ('す', 1466), ('運動', 1467), ('ハウ', 1468), ('ツー', 1469), ('胡散', 1470), ('臭い', 1471), ('眉唾', 1472), ('民間', 1473), ('わん', 1474), ('受けよう', 1475), ('動物', 1476), ('殺す', 1477), ('政府', 1478), ('対応', 1479), ('円', 1480), ('余裕', 1481), ('払う', 1482), ('いとこ', 1483), ('らし', 1484), ('変更', 1485), ('仕方ない', 1486), ('水分', 1487), ('無痛', 1488), ('役所', 1489), ('中世', 1490), ('田谷', 1491), ('区', 1492), ('みな', 1493), ('体温', 1494), ('イラ', 1495), ('色んな', 1496), ('満', 1497), ('まくり', 1498), ('怒ら', 1499), ('バカ', 1500), ('弟熱', 1501), ('こもれ', 1502), ('初詣', 1503), ('格好', 1504), ('起きれ', 1505), ('できつかっ', 1506), ('優しく', 1507), ('気遣っ', 1508), ('辛かっ', 1509), ('悲しく', 1510), ('鼻詰まり', 1511), ('含む', 1512), ('典型', 1513), ('始まっ', 1514), ('夕食', 1515), ('美味し', 1516), ('さらに', 1517), ('撮影', 1518), ('まったく', 1519), ('使っ', 1520), ('あん', 1521), ('旦那', 1522), ('とんでも', 1523), ('いじる', 1524), ('死', 1525), ('かけ', 1526), ('余計', 1527), ('まあ', 1528), ('ズルズル', 1529), ('本人', 1530), ('歌っ', 1531), ('掛かる', 1532), ('寝込み', 1533), ('いやまさか', 1534), ('課題', 1535), ('寝かせ', 1536), ('利く', 1537), ('ちょい', 1538), ('血痰', 1539), ('邪ひい', 1540), ('クシュンクシュン', 1541), ('ありがた', 1542), ('身', 1543), ('しみる', 1544), ('切り上げ', 1545), ('たち', 1546), ('移し', 1547), ('午後', 1548), ('チャック', 1549), ('進捗', 1550), ('聞か', 1551), ('こっ', 1552), ('痰そして', 1553), ('治せ', 1554), ('いちばん', 1555), ('だぁ', 1556), ('アレ', 1557), ('たまら', 1558), ('ブーム', 1559), ('職場', 1560), ('喜べ', 1561), ('バキバキ', 1562), ('詰まっ', 1563), ('逸する', 1564), ('ベッド', 1565), ('過ごし', 1566), ('かない', 1567), ('巻', 1568), ('風邪っ', 1569), ('真っ赤', 1570), ('急い', 1571), ('そこ', 1572), ('タネ', 1573), ('バイト先', 1574), ('だぶっ', 1575), ('アウト', 1576), ('覆う', 1577), ('長風呂', 1578), ('おっ', 1579), ('コレ', 1580), ('混ん', 1581), ('海鮮', 1582), ('動く', 1583), ('ご飯', 1584), ('延期', 1585), ('なこりゃ', 1586), ('ビックリ', 1587), ('炬燵', 1588), ('うたた寝', 1589), ('居る', 1590), ('特集', 1591), ('買い', 1592), ('効い', 1593), ('優し', 1594), ('噴く', 1595), ('通勤', 1596), ('伝える', 1597), ('近く', 1598), ('チーム', 1599), ('キツかっ', 1600), ('判明', 1601), ('休息', 1602), ('テレビニュース', 1603), ('報道', 1604), ('おもい', 1605), ('鼻づまりっ', 1606), ('中々', 1607), ('しかも', 1608), ('吐く', 1609), ('叱る', 1610), ('粗熱', 1611), ('朝目', 1612), ('覚め', 1613), ('何物', 1614), ('猛烈', 1615), ('コンボ', 1616), ('はやく', 1617), ('現在', 1618), ('風呂上がり', 1619), ('髪乾かさ', 1620), ('鼻粘', 1621), ('液', 1622), ('遅刻', 1623), ('服装', 1624), ('涼し', 1625), ('コツ', 1626), ('押さえろ', 1627), ('移っ', 1628), ('仲良く', 1629), ('ほほ', 1630), ('近寄る', 1631), ('曲がり', 1632), ('間違え', 1633), ('しも', 1634), ('回り', 1635), ('彼女', 1636), ('強引', 1637), ('念じ', 1638), ('感じる', 1639), ('まきこま', 1640), ('悪人', 1641), ('渇い', 1642), ('泣き', 1643), ('コンビニ', 1644), ('引きこもり', 1645), ('つらし', 1646), ('溢れ出す', 1647), ('暖かく', 1648), ('移さ', 1649), ('頭曲', 1650), ('がる', 1651), ('溜まっ', 1652), ('便秘', 1653), ('出勤', 1654), ('ましょう', 1655), ('得意', 1656), ('水着', 1657), ('消え', 1658), ('喫茶', 1659), ('遊ん', 1660), ('生水', 1661), ('置い', 1662), ('食べれ', 1663), ('ゆう', 1664), ('単なる', 1665), ('程度', 1666), ('会い', 1667), ('勢い', 1668), ('解放', 1669), ('頭かち', 1670), ('寝言', 1671), ('多分', 1672), ('ハンカチ', 1673), ('失敗', 1674), ('ケンカ', 1675), ('おまけ', 1676), ('ちまう', 1677), ('緊張', 1678), ('ピーク', 1679), ('達し', 1680), ('急激', 1681), ('そんな', 1682), ('のど飴', 1683), ('道', 1684), ('ガンガン', 1685), ('だらだら', 1686), ('現代', 1687), ('叡智', 1688), ('結集', 1689), ('納得', 1690), ('みよう', 1691), ('密', 1692), ('真っ', 1693), ('最中', 1694), ('発', 1695), ('新薬', 1696), ('がち', 1697), ('有難い', 1698), ('弱点', 1699), ('山', 1700), ('頻繁', 1701), ('書類', 1702), ('追加', 1703), ('危うく', 1704), ('危なかっ', 1705), ('はじめて', 1706), ('カラオケ', 1707), ('直そう', 1708), ('センター', 1709), ('復活', 1710), ('からまる', 1711), ('こもり', 1712), ('節電', 1713), ('練り', 1714), ('練っ', 1715), ('強力', 1716), ('完了', 1717), ('息子', 1718), ('損', 1719), ('咳込ん', 1720), ('移動', 1721), ('冷ま', 1722), ('報告', 1723), ('コメント', 1724), ('貰え', 1725), ('うれしい', 1726), ('昨年', 1727), ('水道', 1728), ('直接', 1729), ('こみ上げ', 1730), ('遺伝', 1731), ('弱い', 1732), ('父', 1733), ('そうそして', 1734), ('役立つ', 1735), ('住ん', 1736), ('入れよう', 1737), ('指摘', 1738), ('あげれ', 1739), ('見事', 1740), ('すすっ', 1741), ('うるせー', 1742), ('幼稚', 1743), ('元', 1744), ('カレ', 1745), ('バーベキュー', 1746), ('着用', 1747), ('たまっ', 1748), ('ショック', 1749), ('注意', 1750), ('高く', 1751), ('もっと', 1752), ('打てる', 1753), ('保険', 1754), ('生まれ', 1755), ('このかたお', 1756), ('ふく', 1757), ('衝突', 1758), ('交通', 1759), ('おき', 1760), ('もはや', 1761), ('大食い', 1762), ('次', 1763), ('和らぐ', 1764), ('高校', 1765), ('部', 1766), ('飛ぶ', 1767), ('もらう', 1768), ('よし', 1769), ('サボれる', 1770), ('放置', 1771), ('肉丼', 1772), ('原稿', 1773), ('耐える', 1774), ('毒性', 1775), ('魚', 1776), ('擦', 1777), ('冷やし', 1778), ('何もの', 1779), ('もらわ', 1780), ('伴う', 1781), ('起こす', 1782), ('疑わ', 1783), ('すすめ', 1784), ('有効', 1785), ('殺', 1786), ('話題', 1787), ('羨ましい', 1788), ('社畜', 1789), ('辛い取り敢え', 1790), ('乗り越え', 1791), ('ばっちり', 1792), ('経験', 1793), ('極みついで', 1794), ('血混じり', 1795), ('訴え', 1796), ('うらやましい', 1797), ('近所', 1798), ('あわて', 1799), ('駆け込ん', 1800), ('おかゆ', 1801), ('移せる', 1802), ('技術', 1803), ('うまく', 1804), ('訳せ', 1805), ('無し', 1806), ('残念', 1807), ('相当', 1808), ('からだだるい', 1809), ('だぼっー', 1810), ('ツイート', 1811), ('楽か', 1812), ('クラシック', 1813), ('和らぐん', 1814), ('物語', 1815), ('6', 1816), ('8', 1817), ('出よう', 1818), ('怠', 1819), ('尋常', 1820), ('付き添い', 1821), ('気まず', 1822), ('ちゃい', 1823), ('っぽいー', 1824), ('当たっ', 1825), ('間俺', 1826), ('求む', 1827), ('過剰', 1828), ('反応', 1829), ('おたふくっ', 1830), ('オ', 1831), ('ススメ', 1832), ('夫婦', 1833), ('揃っ', 1834), ('エピソード', 1835), ('直ぐ', 1836), ('おり', 1837), ('ださい', 1838), ('残っ', 1839), ('続ける', 1840), ('アスファルト', 1841), ('耐え', 1842), ('引き鼻水', 1843), ('コンペ', 1844), ('ひき', 1845), ('休んどこう', 1846), ('美人', 1847), ('熱帯', 1848), ('び', 1849), ('けどし', 1850), ('熱怖', 1851), ('下し中ー', 1852), ('紹介', 1853), ('最新', 1854), ('成果', 1855), ('取っ', 1856), ('毎回', 1857), ('吐き出す', 1858), ('守っ', 1859), ('酒', 1860), ('そぼろ', 1861), ('節々', 1862), ('医学', 1863), ('至急', 1864), ('サイン', 1865), ('地面', 1866), ('明後日', 1867), ('勝手', 1868), ('自己', 1869), ('判断', 1870), ('正しい', 1871), ('通り越し', 1872), ('厄介', 1873), ('たび', 1874), ('分かり', 1875), ('かみ', 1876), ('耳炎', 1877), ('よろしく', 1878), ('咳き込み', 1879), ('理解', 1880), ('必ず', 1881), ('音量', 1882), ('こちら', 1883), ('ぞー', 1884), ('あがっ', 1885), ('ひいちゃっ', 1886), ('しより', 1887), ('一層', 1888), ('からみ', 1889), ('消費', 1890), ('おこう', 1891), ('うつっ', 1892), ('発展', 1893), ('防げ', 1894), ('治し', 1895), ('海老', 1896), ('フライ', 1897), ('定食', 1898), ('おいしかっ', 1899), ('良かっ', 1900), ('洋画', 1901), ('描写', 1902), ('吹き', 1903), ('こらえる', 1904), ('上がり', 1905), ('続け', 1906), ('とけ', 1907), ('夫', 1908), ('つく', 1909), ('乾き', 1910), ('突発', 1911), ('起こる', 1912), ('取り', 1913), ('づらく', 1914), ('あー', 1915), ('悪', 1916), ('番', 1917), ('田中', 1918), ('珍しい', 1919), ('引きこもっ', 1920), ('駆け出し', 1921), ('使用', 1922), ('足り', 1923), ('まんねえ', 1924), ('カキ', 1925), ('け', 1926), ('ひっきり', 1927), ('かん', 1928), ('諭す', 1929), ('一言', 1930), ('強がり', 1931), ('遅く', 1932), ('だんだん', 1933), ('胃腸', 1934), ('じゃー', 1935), ('植物', 1936), ('近づか', 1937), ('シーズン', 1938), ('かあ', 1939), ('頼む', 1940), ('過ぎ去れー', 1941), ('十', 1942), ('篭っ', 1943), ('場合', 1944), ('どなた', 1945), ('乗る', 1946), ('発疹', 1947), ('やばいとりあえず', 1948), ('やすみ', 1949), ('渡す', 1950), ('触っ', 1951), ('熱嫁', 1952), ('腹く', 1953), ('勃発', 1954), ('学級', 1955), ('閉鎖', 1956), ('愛用', 1957), ('発想', 1958), ('いまいち', 1959), ('治り', 1960), ('にくく', 1961), ('メンバー', 1962), ('一段', 1963), ('息苦しい', 1964), ('味', 1965), ('萎える', 1966), ('っしょ', 1967), ('住む', 1968), ('うなさ', 1969), ('投稿', 1970), ('怖く', 1971), ('めった', 1972), ('掃除', 1973), ('癒さ', 1974), ('外食', 1975), ('小説', 1976), ('本日', 1977), ('落ち込ん', 1978), ('結果', 1979), ('カツ丼', 1980), ('付き', 1981), ('メール', 1982), ('なれ', 1983), ('フラフラ', 1984), ('すー', 1985), ('とか', 1986), ('告げ', 1987), ('みたく', 1988), ('気合い', 1989), ('引か', 1990), ('服', 1991), ('着', 1992), ('雑誌', 1993), ('経路', 1994), ('不明', 1995), ('ゲホゲホ', 1996), ('なんなん', 1997), ('守れ', 1998), ('箋', 1999), ('徐々', 2000), ('嗅覚', 2001), ('すっごく', 2002), ('歩い', 2003), ('ノロ', 2004), ('持続', 2005), ('長い', 2006), ('意識', 2007), ('ばし止まる', 2008), ('ヒドい', 2009), ('着ぐるみ', 2010), ('着せ', 2011), ('結局', 2012), ('ごまかし', 2013), ('長引', 2014), ('くらしい', 2015), ('写らん', 2016), ('未満', 2017), ('間違っ', 2018), ('締め付け', 2019), ('られる', 2020), ('感覚', 2021), ('到来', 2022), ('やすむ', 2023), ('だだるい', 2024), ('暑い', 2025), ('求め', 2026), ('クーラー', 2027), ('設置', 2028), ('冷房', 2029), ('病', 2030), ('たり', 2031), ('新入', 2032), ('社員', 2033), ('まくる', 2034), ('見舞い', 2035), ('空い', 2036), ('たって', 2037), ('がっつい', 2038), ('一旦', 2039), ('最低', 2040), ('限', 2041), ('はやっ', 2042), ('牛乳', 2043), ('こわっ', 2044), ('出会える', 2045), ('キレイ', 2046), ('風景', 2047), ('会話', 2048), ('盛ら', 2049), ('うっ', 2050), ('っす', 2051), ('おば', 2052), ('キライー', 2053), ('ひく', 2054), ('判別', 2055), ('難い', 2056), ('悲しい', 2057), ('泣か', 2058), ('連れ', 2059), ('終わら', 2060), ('せよう', 2061), ('毎朝', 2062), ('気なし', 2063), ('肋骨', 2064), ('骨折', 2065), ('予感', 2066), ('入り寝る', 2067), ('月曜', 2068), ('友人', 2069), ('クラス', 2070), ('逃げ', 2071), ('こえぇ', 2072), ('向かっ', 2073), ('観念', 2074), ('潜っ', 2075), ('飽き', 2076), ('読み', 2077), ('人居', 2078), ('せめて', 2079), ('口押さえる', 2080), ('たっ', 2081), ('薬のん', 2082), ('ゲーム', 2083), ('いわ', 2084), ('やんなっ', 2085), ('おいしい', 2086), ('グルメ', 2087), ('巡り', 2088), ('合わん', 2089), ('習っ', 2090), ('黄砂', 2091), ('流行り', 2092), ('だす', 2093), ('打とう', 2094), ('変わり', 2095), ('話し', 2096), ('もらえる', 2097), ('すっごい', 2098), ('夏', 2099), ('おかしい', 2100), ('インフルザエンザ', 2101), ('思い出せ', 2102), ('大量', 2103), ('様子', 2104), ('不満', 2105), ('薬局', 2106), ('思い出', 2107), ('ふらふら', 2108), ('無念', 2109), ('こじら', 2110), ('食わ', 2111), ('他人', 2112), ('触れる', 2113), ('加え鼻づまり', 2114), ('呼吸', 2115), ('乾い', 2116), ('スケジュール', 2117), ('常', 2118), ('先輩', 2119), ('失態', 2120), ('犯し', 2121), ('つける', 2122), ('入院', 2123), ('鎮痛', 2124), ('レベル', 2125), ('確認', 2126), ('良薬', 2127), ('参り', 2128), ('選', 2129), ('書か', 2130), ('発生', 2131), ('あきらめ', 2132), ('押さえ', 2133), ('運転', 2134), ('ぐったり', 2135), ('再来', 2136), ('すん', 2137), ('炎症', 2138), ('よすごい', 2139), ('鼻づまり目', 2140), ('痒み', 2141), ('異常', 2142), ('件', 2143), ('時水', 2144), ('合わ', 2145), ('くらくらし', 2146), ('日課', 2147), ('作れ', 2148), ('口元', 2149), ('買わ', 2150), ('陽気', 2151), ('下っ', 2152), ('左右', 2153), ('どちら', 2154), ('既に', 2155), ('座っ', 2156), ('人手', 2157), ('迷惑', 2158), ('はい', 2159), ('引くん', 2160), ('以来', 2161)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 30\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "embedding_matrix = np.zeros((vocab_size,EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > vocab_size:\n",
    "        continue\n",
    "    embedding_vector = word_vectors[word]\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 30, 100)           216200    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 28, 128)           38528     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14, 32)            4128      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 3592      \n",
      "=================================================================\n",
      "Total params: 262,448\n",
      "Trainable params: 262,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                     EMBEDDING_DIM,\n",
    "                     mask_zero=False,\n",
    "                     embeddings_initializer=Constant(embedding_matrix),\n",
    "                     input_length=maxlen,\n",
    "                     trainable=True)\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"Influenza\", \"Diarrhea\",\"Hayfever\",\"Cough\",\"Headache\",\"Fever\",\"Runnynose\",\"Cold\"]\n",
    "result_train = train_ja[list_classes].replace({'n':0, 'p':+1})\n",
    "y_train = result_train[list_classes].values\n",
    "\n",
    "result_test = test_ja[list_classes].replace({'n':0, 'p':+1})\n",
    "y_test = result_test[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 640 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.5086 - accuracy: 0.8438 - val_loss: 0.3716 - val_accuracy: 0.8834\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.3778 - accuracy: 0.8754 - val_loss: 0.3558 - val_accuracy: 0.8834\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.3651 - accuracy: 0.8754 - val_loss: 0.3528 - val_accuracy: 0.8834\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.3601 - accuracy: 0.8754 - val_loss: 0.3488 - val_accuracy: 0.8834\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.3543 - accuracy: 0.8754 - val_loss: 0.3443 - val_accuracy: 0.8834\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.3432 - accuracy: 0.8754 - val_loss: 0.3321 - val_accuracy: 0.8834\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.3230 - accuracy: 0.8774 - val_loss: 0.3093 - val_accuracy: 0.8869\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.2942 - accuracy: 0.8841 - val_loss: 0.2854 - val_accuracy: 0.8953\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2626 - accuracy: 0.8902 - val_loss: 0.2598 - val_accuracy: 0.8984\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2342 - accuracy: 0.9005 - val_loss: 0.2434 - val_accuracy: 0.9049\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.2074 - accuracy: 0.9156 - val_loss: 0.2272 - val_accuracy: 0.9107\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.1837 - accuracy: 0.9281 - val_loss: 0.2095 - val_accuracy: 0.9193\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1616 - accuracy: 0.9396 - val_loss: 0.1958 - val_accuracy: 0.9236\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1392 - accuracy: 0.9514 - val_loss: 0.1777 - val_accuracy: 0.9332\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1206 - accuracy: 0.9623 - val_loss: 0.1682 - val_accuracy: 0.9379\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1053 - accuracy: 0.9683 - val_loss: 0.1627 - val_accuracy: 0.9424\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0935 - accuracy: 0.9724 - val_loss: 0.1558 - val_accuracy: 0.9453\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0839 - accuracy: 0.9755 - val_loss: 0.1516 - val_accuracy: 0.9455\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0732 - accuracy: 0.9796 - val_loss: 0.1475 - val_accuracy: 0.9475\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0654 - accuracy: 0.9818 - val_loss: 0.1498 - val_accuracy: 0.9463\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0590 - accuracy: 0.9835 - val_loss: 0.1473 - val_accuracy: 0.9502\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0527 - accuracy: 0.9859 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0464 - accuracy: 0.9880 - val_loss: 0.1483 - val_accuracy: 0.9498\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0422 - accuracy: 0.9898 - val_loss: 0.1449 - val_accuracy: 0.9492\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0373 - accuracy: 0.9909 - val_loss: 0.1430 - val_accuracy: 0.9541\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0335 - accuracy: 0.9917 - val_loss: 0.1460 - val_accuracy: 0.9527\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.1452 - val_accuracy: 0.9508\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.1457 - val_accuracy: 0.9520\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.1456 - val_accuracy: 0.9551\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0213 - accuracy: 0.9957 - val_loss: 0.1456 - val_accuracy: 0.9537\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.1442 - val_accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=6,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ") # add early stopping\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_test, y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influenza\n",
      "\n",
      "Test accuracy is 0.9765625\n",
      "Test precision is 0.7647058823529411\n",
      "Test recall is 0.5416666666666666\n",
      "Test f1-score is 0.6341463414634146\n",
      "\n",
      "Diarrhea\n",
      "\n",
      "Test accuracy is 0.9625\n",
      "Test precision is 0.8703703703703703\n",
      "Test recall is 0.734375\n",
      "Test f1-score is 0.7966101694915254\n",
      "\n",
      "Hayfever\n",
      "\n",
      "Test accuracy is 0.975\n",
      "Test precision is 0.8125\n",
      "Test recall is 0.8478260869565217\n",
      "Test f1-score is 0.8297872340425533\n",
      "\n",
      "Cough\n",
      "\n",
      "Test accuracy is 0.9671875\n",
      "Test precision is 0.927536231884058\n",
      "Test recall is 0.8\n",
      "Test f1-score is 0.8590604026845639\n",
      "\n",
      "Headache\n",
      "\n",
      "Test accuracy is 0.9703125\n",
      "Test precision is 0.9264705882352942\n",
      "Test recall is 0.8181818181818182\n",
      "Test f1-score is 0.8689655172413794\n",
      "\n",
      "Fever\n",
      "\n",
      "Test accuracy is 0.91875\n",
      "Test precision is 0.7733333333333333\n",
      "Test recall is 0.6236559139784946\n",
      "Test f1-score is 0.6904761904761905\n",
      "\n",
      "Runnynose\n",
      "\n",
      "Test accuracy is 0.9390625\n",
      "Test precision is 0.8888888888888888\n",
      "Test recall is 0.7804878048780488\n",
      "Test f1-score is 0.8311688311688312\n",
      "\n",
      "Cold\n",
      "\n",
      "Test accuracy is 0.9234375\n",
      "Test precision is 0.8596491228070176\n",
      "Test recall is 0.5444444444444444\n",
      "Test f1-score is 0.6666666666666667\n",
      "\n",
      "Summary\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "The average accuracy is 0.9541015625000001\n",
      "The average precision is 0.8529318022339878\n",
      "The average recall is 0.7113297168882493\n",
      "The average f1 score is 0.7721101691543907\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "pred_test = model.predict(X_test)\n",
    "classes = pred_test > 0.5\n",
    "pred_test = classes.astype(int) # update predicted value\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# initialize\n",
    "ac = 0 \n",
    "pre = 0\n",
    "rec = 0\n",
    "f1_s = 0\n",
    "\n",
    "for i in range (0,8):\n",
    "    \n",
    "    prediction = pred_test[:, i]\n",
    "    y_sys = y_test[:,i]\n",
    "    print(list_classes[i])\n",
    "    print('\\nTest accuracy is {}'.format(accuracy_score(y_sys, prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(y_sys, prediction, average='binary')))\n",
    "    print('Test recall is {}'.format(recall_score(y_sys, prediction, average='binary')))\n",
    "    print('Test f1-score is {}\\n'.format(f1_score(y_sys, prediction, average='binary')))\n",
    "    \n",
    "    temp_accuracy = accuracy_score(y_sys, prediction)\n",
    "    ac = ac + temp_accuracy\n",
    "    \n",
    "    temp_precision = precision_score(y_sys, prediction, average='binary')\n",
    "    pre = pre + temp_precision\n",
    "    \n",
    "    temp_recall = recall_score(y_sys, prediction, average='binary')\n",
    "    rec = rec + temp_recall\n",
    "    \n",
    "    temp_f1_score = f1_score(y_sys, prediction, average='binary')\n",
    "    f1_s= f1_s + temp_f1_score\n",
    "\n",
    "print(\"Summary\\n>>>>>>>>>>>>>>>>>>>>>\\n\")\n",
    "ava_accuracy = ac/8\n",
    "print('The average accuracy is {}'.format(ava_accuracy))\n",
    "\n",
    "ava_precision = pre/8\n",
    "print('The average precision is {}'.format(ava_precision))\n",
    "\n",
    "ava_recall = rec/8\n",
    "print('The average recall is {}'.format(ava_recall))\n",
    "\n",
    "ava_f1_score = f1_s/8\n",
    "print('The average f1 score is {}'.format(ava_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label='Test accuracy')\n",
    "    plt.title('Training and testing accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Test loss')\n",
    "    plt.title('Training and testing loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CNN_jap.jpg\")\n",
    "    \n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
