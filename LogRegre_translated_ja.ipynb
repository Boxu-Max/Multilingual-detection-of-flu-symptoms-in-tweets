{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 2016 unique tokens\n",
      "**Processing Influenza sysptoms...**\n",
      "Test accuracy is 0.9671875\n",
      "Test precision is 0.6153846153846154\n",
      "Test recall is 0.3333333333333333\n",
      "Test f1-score is 0.43243243243243246\n",
      "\n",
      "**Processing Diarrhea sysptoms...**\n",
      "Test accuracy is 0.9734375\n",
      "Test precision is 0.8133333333333334\n",
      "Test recall is 0.953125\n",
      "Test f1-score is 0.8776978417266187\n",
      "\n",
      "**Processing Hayfever sysptoms...**\n",
      "Test accuracy is 0.928125\n",
      "Test precision is 0.0\n",
      "Test recall is 0.0\n",
      "Test f1-score is 0.0\n",
      "\n",
      "**Processing Cough sysptoms...**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boxulu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/boxulu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9765625\n",
      "Test precision is 0.9012345679012346\n",
      "Test recall is 0.9125\n",
      "Test f1-score is 0.9068322981366459\n",
      "\n",
      "**Processing Headache sysptoms...**\n",
      "Test accuracy is 0.975\n",
      "Test precision is 0.8426966292134831\n",
      "Test recall is 0.974025974025974\n",
      "Test f1-score is 0.9036144578313253\n",
      "\n",
      "**Processing Fever sysptoms...**\n",
      "Test accuracy is 0.8984375\n",
      "Test precision is 0.6891891891891891\n",
      "Test recall is 0.5483870967741935\n",
      "Test f1-score is 0.6107784431137725\n",
      "\n",
      "**Processing Runnynose sysptoms...**\n",
      "Test accuracy is 0.934375\n",
      "Test precision is 0.8461538461538461\n",
      "Test recall is 0.8048780487804879\n",
      "Test f1-score is 0.8250000000000001\n",
      "\n",
      "**Processing Cold sysptoms...**\n",
      "Test accuracy is 0.9359375\n",
      "Test precision is 0.7333333333333333\n",
      "Test recall is 0.8555555555555555\n",
      "Test f1-score is 0.7897435897435897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# English translate to Japanese\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_from_en = pd.read_csv(\"NTCIR-13_MedWeb_ja_from_en_amazon_training.csv\")\n",
    "test = pd.read_csv(\"NTCIR-13_MedWeb_ja_test.csv\", na_values='NaN',keep_default_na=False)\n",
    "\n",
    "# remove punctuations inside\n",
    "import re\n",
    "from zhon.hanzi import punctuation\n",
    "\n",
    "def clean_text(df, text_field):\n",
    "    \n",
    "    df[text_field] = df[text_field].apply(lambda elem:re.sub(r'[{}]+'.format(punctuation),'',elem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# update\n",
    "\n",
    "train_from_en = clean_text(train_from_en,\"Tweet\")\n",
    "test = clean_text(test,\"Tweet\")\n",
    "\n",
    "tweet_train_from_en = list(train_from_en.Tweet)\n",
    "tweet_test = list(test.Tweet)\n",
    "\n",
    "# Add Japanese tokenizer\n",
    "import nagisa\n",
    "\n",
    "def tokenize_jp(doc):\n",
    "    doc = nagisa.tagging(doc)\n",
    "    return doc.words\n",
    "\n",
    "# define labels\n",
    "categories = ['Influenza','Diarrhea','Hayfever','Cough','Headache','Fever','Runnynose','Cold']\n",
    "\n",
    "y_train = train_from_en[categories].replace({'n':0, 'p':+1})\n",
    "y_test = test[categories].replace({'n':0, 'p':+1})\n",
    "\n",
    "# BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = ['!','0','1','2','3','4','6','8','9','?','、','。','〜','・','(',')',',','-','.','...','/']\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_jp, stop_words=stop_words)\n",
    "X_train = vectorizer.fit_transform(tweet_train_from_en).toarray()\n",
    "\n",
    "feature = vectorizer.get_feature_names()\n",
    "\n",
    "vectorizer_test = CountVectorizer(tokenizer=tokenize_jp,vocabulary=vectorizer.vocabulary_)\n",
    "X_test = vectorizer_test.transform(tweet_test).toarray()\n",
    "\n",
    "print(\"The vocabulary contains {} unique tokens\".format(len(feature)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(C=10, solver='lbfgs', penalty='l2', max_iter=2500, class_weight='balanced'), n_jobs=-1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('**Processing {} sysptoms...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(X_train, y_train[category].values)\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test[category], prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(y_test[category], prediction, average='binary')))\n",
    "    print('Test recall is {}'.format(recall_score(y_test[category], prediction, average='binary')))\n",
    "    print('Test f1-score is {}\\n'.format(f1_score(y_test[category], prediction, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 2052 unique tokens\n",
      "**Processing Influenza sysptoms...**\n",
      "Test accuracy is 0.95625\n",
      "Test precision is 0.4\n",
      "Test recall is 0.3333333333333333\n",
      "Test f1-score is 0.3636363636363636\n",
      "\n",
      "**Processing Diarrhea sysptoms...**\n",
      "Test accuracy is 0.9703125\n",
      "Test precision is 0.8\n",
      "Test recall is 0.9375\n",
      "Test f1-score is 0.8633093525179856\n",
      "\n",
      "**Processing Hayfever sysptoms...**\n",
      "Test accuracy is 0.978125\n",
      "Test precision is 0.7758620689655172\n",
      "Test recall is 0.9782608695652174\n",
      "Test f1-score is 0.8653846153846154\n",
      "\n",
      "**Processing Cough sysptoms...**\n",
      "Test accuracy is 0.9828125\n",
      "Test precision is 0.9156626506024096\n",
      "Test recall is 0.95\n",
      "Test f1-score is 0.9325153374233127\n",
      "\n",
      "**Processing Headache sysptoms...**\n",
      "Test accuracy is 0.971875\n",
      "Test precision is 0.8241758241758241\n",
      "Test recall is 0.974025974025974\n",
      "Test f1-score is 0.8928571428571428\n",
      "\n",
      "**Processing Fever sysptoms...**\n",
      "Test accuracy is 0.871875\n",
      "Test precision is 0.5555555555555556\n",
      "Test recall is 0.5913978494623656\n",
      "Test f1-score is 0.5729166666666666\n",
      "\n",
      "**Processing Runnynose sysptoms...**\n",
      "Test accuracy is 0.9265625\n",
      "Test precision is 0.796875\n",
      "Test recall is 0.8292682926829268\n",
      "Test f1-score is 0.8127490039840638\n",
      "\n",
      "**Processing Cold sysptoms...**\n",
      "Test accuracy is 0.9453125\n",
      "Test precision is 0.8395061728395061\n",
      "Test recall is 0.7555555555555555\n",
      "Test f1-score is 0.7953216374269005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chinese translate to Japanese\n",
    "train_from_zh = pd.read_csv(\"NTCIR-13_MedWeb_ja_from_zh_amazon_training.csv\")\n",
    "\n",
    "# update\n",
    "train_from_zh = clean_text(train_from_zh,\"Tweet\")\n",
    "tweet_train_from_zh = list(train_from_zh.Tweet)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = ['!','0','1','2','3','4','6','8','9','?','、','。','〜','・','(',')',',','-','.','...','/']\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_jp, stop_words=stop_words)\n",
    "X_train = vectorizer.fit_transform(tweet_train_from_zh).toarray()\n",
    "\n",
    "feature = vectorizer.get_feature_names()\n",
    "\n",
    "vectorizer_test = CountVectorizer(tokenizer=tokenize_jp,vocabulary=vectorizer.vocabulary_)\n",
    "X_test = vectorizer_test.transform(tweet_test).toarray()\n",
    "\n",
    "print(\"The vocabulary contains {} unique tokens\".format(len(feature)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(C=10, solver='lbfgs', penalty='l2', max_iter=2500, class_weight='balanced'), n_jobs=-1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('**Processing {} sysptoms...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(X_train, y_train[category].values)\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test[category], prediction)))\n",
    "    print('Test precision is {}'.format(precision_score(y_test[category], prediction, average='binary')))\n",
    "    print('Test recall is {}'.format(recall_score(y_test[category], prediction, average='binary')))\n",
    "    print('Test f1-score is {}\\n'.format(f1_score(y_test[category], prediction, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
